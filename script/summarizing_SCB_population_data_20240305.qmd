---
title: "summarizing SCB population data"
format: html
editor: source
---

Summarizing population data from datsets 1995-2023 into five years and weighded mean over all years. read in data, create categorical varaibles, , extract thos who are in the HPI dataset into an own dataset via the LopNr variable and then summarize percentages of different variables into five year groups.

To accurately calculate a weighted mean, which accounts for the varying sizes of each group across periods, you can use the following formula:

$$
\text{Weighted Mean} = \frac{\sum (W_i \times X_i)}{\sum W_i}
$$

Where:

-   $W_i$ is the weight for period $i$ (in this context, the total count for the variable in the period),
-   $X_i$ is the percentage value for the variable in period $i$,
-   The summation ($\sum$) runs over all periods.

# Example Calculation

Suppose we have three five-year periods with the following percentages of males and total populations:

-   Period 1: 60% males (with 200 individuals in total)
-   Period 2: 55% males (with 300 individuals in total)
-   Period 3: 50% males (with 500 individuals in total)

We can calculate the weighted mean percentage of males across all periods as follows:

```{r}
# Define the percentages and populations
percentages <- c(60, 55, 50)
populations <- c(200, 300, 500)

# Calculate the weighted mean
weighted_mean <- sum(percentages * populations) / sum(populations)

# Print the result
weighted_mean



```



script 1



script 2
1. Run 1.1
2. Run 1.2
3. Run 2.1


```{r}
library(tidyverse)
library(haven)
library(here)
```

```{r}

hpa <- read_csv(here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "HPI", "HPI clean", "EEB_hpb_clean_2023-10-16.csv")) %>% select(LopNr)



scb_grunduppgifter <- 
haven::read_sas(here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306","Leverans002", "eeb_lev_grunduppgifter.sas7bdat"))


scb_2022 <- 
haven::read_sas(here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306","Leverans1990_2022", "eeb_lev_2022.sas7bdat"))

scb_2021 <- 
haven::read_sas(here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306","Leverans1990_2022", "eeb_lev_2021.sas7bdat"))

scb_1997 <- 
haven::read_sas(here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306","Leverans1990_2022", "eeb_lev_1997.sas7bdat"))

scb_1996 <- 
haven::read_sas(here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306","Leverans1990_2022", "eeb_lev_1996.sas7bdat"))

scb_2015 <- 
haven::read_sas(here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306","Leverans1990_2022", "eeb_lev_2015.sas7bdat"))
scb_2016 <- 
haven::read_sas(here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306","Leverans1990_2022", "eeb_lev_2016.sas7bdat"))
scb_2017 <- 
haven::read_sas(here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306","Leverans1990_2022", "eeb_lev_2017.sas7bdat"))
scb_2019 <- 
haven::read_sas(here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306","Leverans1990_2022", "eeb_lev_2019.sas7bdat"))

scb_2002 <- 
haven::read_sas(here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306","Leverans1990_2022", "eeb_lev_2002.sas7bdat"))


scb_1997 <- 
haven::read_sas(here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306","Leverans1990_2022", "eeb_lev_1997.sas7bdat"))









scb_2015 %>%
   filter(str_detect(Ssyk3_2012_J16, "^22")) %>%
  count(Missing=is.na(Ftg_Nettoomsattning)) %>% mutate(Percentage=n/sum(n)*100)



scb_2015 %>%
   filter(str_detect(Ssyk3_2012_J16, "^21")) %>%
  count(Missing=is.na(Ftg_Nettoomsattning)) %>% mutate(Percentage=n/sum(n)*100)














scb_2012 %>% 
  mutate(Year =2012,
    Ssyk3_minorlevel = if (length(grep("^Ssyk3", names(.))) > 0) {
      as.numeric(str_extract(.[[grep("^Ssyk3", names(.))[[1]]]], "\\d+"))
    } else NA_real_, # Using NA_real_ to explicitly denote numeric NA
  Ssyk2_submajorlevel = as.numeric(str_sub(Ssyk3_minorlevel, end = 2)),
  Ssyk1_majorlevel = as.numeric(str_sub(Ssyk3_minorlevel, end = 1)),
    SSYK = if ("Ssyk3_minorlevel" %in% names(.)) {
    #  if ("Year" %in% names(.) && all(c("Ssyk1_majorlevel", "Ssyk2_submajorlevel", "Ssyk3_minorlevel") %in% names(.))) {
      case_when(
         !is.na(Ssyk1_majorlevel) & Ssyk1_majorlevel == "0" & Year < 2014 ,
      !is.na(Ssyk1_majorlevel) & Ssyk1_majorlevel == "1" & Year < 2014 ~ "Managers",
        Year < 2014 & Ssyk2_submajorlevel == 21 ~ "Science and engineering",
        Year < 2014 & Ssyk2_submajorlevel == 22 ~ "Health care",
        Ssyk2_submajorlevel == 23 ~ "Education",
        Year < 2014 & Ssyk2_submajorlevel >= 24 & Ssyk2_submajorlevel < 30 ~ "Other professionals",
        Year < 2014 & Ssyk1_majorlevel == 3 ~ "Associate professionals",
        Year < 2014 & Ssyk1_majorlevel == 4 ~ "Administration and customer service",
        Year < 2014 & Ssyk3_minorlevel == 513  ~ "Personal care",
        Year < 2014 & str_starts(as.character(Ssyk3_minorlevel), "5") ~ "Service and shop sales",
        Year < 2014 & Ssyk1_majorlevel == 6 ~ "Agriculture and forestry",
        Year < 2014 & Ssyk2_submajorlevel == 71 ~ "Building",
        Year < 2014 & Ssyk2_submajorlevel > 71 & Ssyk2_submajorlevel < 80 ~ "Manufacturing",
        Year < 2014 & Ssyk2_submajorlevel == 83 ~ "Transport",
        Year < 2014 & (Ssyk2_submajorlevel >= 80 & Ssyk2_submajorlevel < 83 | Ssyk2_submajorlevel >= 84 & Ssyk2_submajorlevel < 90) ~ "Mechanical manufacturing",
        Year < 2014 & Ssyk2_submajorlevel == 91 ~ "Cleaners",
        Year < 2014 & Ssyk2_submajorlevel > 91 ~ "Other elementary occupations",
        
        Year >= 2014 & Ssyk1_majorlevel == 0 ~ "Military",
        Year >= 2014 & Ssyk1_majorlevel == 1 ~ "Managers",
        Year >= 2014 & Ssyk2_submajorlevel == 21 ~ "Science and engineering",
        Year >= 2014 & Ssyk2_submajorlevel == 22 ~ "Health care",
        Year >= 2014 & Ssyk2_submajorlevel == 23 ~ "Education",
        Year >= 2014 & Ssyk2_submajorlevel >= 24 & Ssyk2_submajorlevel < 30 ~ "Other professionals",
        Year >= 2014 & Ssyk1_majorlevel == 3 ~ "Associate professionals",
        Year >= 2014 & Ssyk1_majorlevel == 4 ~ "Administration and customer service",
        Year >= 2014 & Ssyk2_submajorlevel == 53 ~ "Personal care",
        Year >= 2014 & (Ssyk2_submajorlevel > 50 & Ssyk2_submajorlevel < 54 | Ssyk2_submajorlevel >= 54 & Ssyk2_submajorlevel < 60) ~ "Service and shop sales",
        Year >= 2014 & Ssyk1_majorlevel == 6 ~ "Agriculture and forestry",
        Year >= 2014 & Ssyk2_submajorlevel == 71 ~ "Building",
        Year >= 2014 & Ssyk2_submajorlevel > 71 & Ssyk2_submajorlevel < 80 ~ "Manufacturing",
        Year >= 2014 & Ssyk2_submajorlevel == 83 ~ "Transport",
        Year >= 2014 & (Ssyk2_submajorlevel >= 80 & Ssyk2_submajorlevel < 83 | Ssyk2_submajorlevel >= 84 & Ssyk2_submajorlevel < 90) ~ "Mechanical manufacturing",
        Year >= 2014 & Ssyk2_submajorlevel == 91 ~ "Cleaners",
        Year >= 2014 & Ssyk2_submajorlevel > 91 ~ "Other elementary occupations",
        
        TRUE ~ NA_character_
      )
    } else NA_character_ ) %>% 
  select(Ssyk1_majorlevel, Ssyk2_submajorlevel, Ssyk3_minorlevel, SSYK)


 scb_2012 %>% #select(!c(Ssyk3, Ssyk3_J16)) %>% 
  mutate(Year=2012,
    # extracting cols that begins with Ssyk3 and 
    Ssyk3_minorlevel = if (length(grep("^Ssyk3", names(.))) > 0) {
      as.numeric(str_extract(.[[grep("^Ssyk3", names(.))[[1]]]], "\\d+"))
    } else NA_real_,  # Using NA_real_ to explicitly denote numeric NA
    Ssyk2_submajorlevel = as.numeric(str_sub(Ssyk3_minorlevel, end = 2)),
    Ssyk1_majorlevel = as.numeric(str_sub(Ssyk3_minorlevel, end = 1)),
    SSYK = case_when(
      # SSYK96, pre 2014
      Year < 2014 & Ssyk1_majorlevel == 0 ~ "Military",
      Year < 2014 & Ssyk1_majorlevel == 1 ~ "Managers",
      Year < 2014 & Ssyk2_submajorlevel == 21 ~ "Science and engineering",
      Year < 2014 & Ssyk2_submajorlevel == 22 ~ "Health care",
      Year < 2014 & Ssyk2_submajorlevel == 23 ~ "Education",
      Year < 2014 & Ssyk2_submajorlevel >= 24 & Ssyk2_submajorlevel < 30 ~ "Other professionals",
      Year < 2014 & Ssyk1_majorlevel == 3 ~ "Associate professionals",
      Year < 2014 & Ssyk1_majorlevel == 4 ~ "Administration and customer service",
      Year < 2014 & Ssyk3_minorlevel == 513 ~ "Personal care",
      Year < 2014 & str_starts(as.character(Ssyk3_minorlevel), "5") ~ "Service and shop sales",
      Year < 2014 & Ssyk1_majorlevel == 6 ~ "Agriculture and forestry",
      Year < 2014 & Ssyk2_submajorlevel == 71 ~ "Building",
      Year < 2014 & Ssyk2_submajorlevel > 71 & Ssyk2_submajorlevel < 80 ~ "Manufacturing",
      Year < 2014 & Ssyk2_submajorlevel == 83 ~ "Transport",
      Year < 2014 & (Ssyk2_submajorlevel >= 80 & Ssyk2_submajorlevel < 83 | Ssyk2_submajorlevel >= 84 & Ssyk2_submajorlevel < 90) ~ "Mechanical manufacturing",
      Year < 2014 & Ssyk2_submajorlevel == 91 ~ "Cleaners",
      Year < 2014 & Ssyk2_submajorlevel > 91 ~ "Other elementary occupations",
      # SSYK2012, post 2013
      Year >= 2014 & Ssyk1_majorlevel == 0 ~ "Military",
      Year >= 2014 & Ssyk1_majorlevel == 1 ~ "Managers",
      Year >= 2014 & Ssyk2_submajorlevel == 21 ~ "Science and engineering",
      Year >= 2014 & Ssyk2_submajorlevel == 22 ~ "Health care",
      Year >= 2014 & Ssyk2_submajorlevel == 23 ~ "Education",
      Year >= 2014 & Ssyk2_submajorlevel >= 24 & Ssyk2_submajorlevel < 30 ~ "Other professionals",
      Year >= 2014 & Ssyk1_majorlevel == 3 ~ "Associate professionals",
      Year >= 2014 & Ssyk1_majorlevel == 4 ~ "Administration and customer service",
      Year >= 2014 & Ssyk2_submajorlevel == 53 ~ "Personal care",
      Year >= 2014 & (Ssyk2_submajorlevel > 50 & Ssyk2_submajorlevel < 54 | Ssyk2_submajorlevel >= 54 & Ssyk2_submajorlevel < 60) ~ "Service and shop sales",
      Year >= 2014 & Ssyk1_majorlevel == 6 ~ "Agriculture and forestry",
      Year >= 2014 & Ssyk2_submajorlevel == 71 ~ "Building",
      Year >= 2014 & Ssyk2_submajorlevel > 71 & Ssyk2_submajorlevel < 80 ~ "Manufacturing",
      Year >= 2014 & Ssyk2_submajorlevel == 83 ~ "Transport",
      Year >= 2014 & (Ssyk2_submajorlevel >= 80 & Ssyk2_submajorlevel < 83 | Ssyk2_submajorlevel >= 84 & Ssyk2_submajorlevel < 90) ~ "Mechanical manufacturing",
      Year >= 2014 & Ssyk2_submajorlevel == 91 ~ "Cleaners",
      Year >= 2014 & Ssyk2_submajorlevel > 91 ~ "Other elementary occupations",
      TRUE ~ NA_character_
    )
  ) %>%
  select(Year, Ssyk1_majorlevel, Ssyk2_submajorlevel, Ssyk3_minorlevel, SSYK) #%>% count(is.na(Ssyk3_minorlevel))

 
 
  mutate(
    Year = 2012,
    Ssyk3_minorlevel = if (length(grep("^Ssyk3", names(.))) > 0) {
      as.numeric(str_extract(.[[grep("^Ssyk3", names(.))[[1]]]], "\\d+"))
    } else NA_real_,
    Ssyk2_submajorlevel = as.numeric(str_sub(Ssyk3_minorlevel, end = 2)),
    Ssyk1_majorlevel = as.numeric(str_sub(Ssyk3_minorlevel, end = 1)),
    SSYK = case_when(
      !is.na(Ssyk1_majorlevel) & Ssyk1_majorlevel == 0 & Year < 2014 ~ "Military",
      !is.na(Ssyk1_majorlevel) & Ssyk1_majorlevel == 1 & Year < 2014 ~ "Managers",
      !is.na(Ssyk2_submajorlevel) & Ssyk2_submajorlevel == 21 & Year < 2014 ~ "Science and engineering",
      !is.na(Ssyk2_submajorlevel) & Ssyk2_submajorlevel == 22 & Year < 2014 ~ "Health care",
      !is.na(Ssyk2_submajorlevel) & Ssyk2_submajorlevel == 23 & Year < 2014 ~ "Education",
      !is.na(Ssyk2_submajorlevel) & Ssyk2_submajorlevel >= 24 & Ssyk2_submajorlevel < 30 & Year < 2014 ~ "Other professionals",
      !is.na(Ssyk1_majorlevel) & Ssyk1_majorlevel == 0 & Year >= 2014 ~ "Military",
      !is.na(Ssyk1_majorlevel) & Ssyk1_majorlevel == 1 & Year >= 2014 ~ "Managers",
      !is.na(Ssyk2_submajorlevel) & Ssyk2_submajorlevel == 21 & Year >= 2014 ~ "Science and engineering",
      !is.na(Ssyk2_submajorlevel) & Ssyk2_submajorlevel == 22 & Year >= 2014 ~ "Health care",
      !is.na(Ssyk2_submajorlevel) & Ssyk2_submajorlevel == 23 & Year >= 2014 ~ "Education",
      !is.na(Ssyk2_submajorlevel) & Ssyk2_submajorlevel >= 24 & Ssyk2_submajorlevel < 30 & Year >= 2014 ~ "Other professionals",
      TRUE ~ NA_character_
    )
  ) %>% 
  select(Ssyk1_majorlevel, Ssyk2_submajorlevel, Ssyk3_minorlevel, SSYK)

  mutate(
     operatingprofit= case_when(
    Ftg_Rorelseresultat > 1.5 * median(Ftg_Rorelseresultat, na.rm = TRUE) ~ "High Profit",
    Ftg_Rorelseresultat > 0 & Ftg_Rorelseresultat <= 1.5 * median(Ftg_Rorelseresultat, na.rm = TRUE) ~ "Moderate Profit",
    Ftg_Rorelseresultat == 0 ~ "No Change",
    Ftg_Rorelseresultat < 0 & Ftg_Rorelseresultat >= 1.5 * median(Ftg_Rorelseresultat, na.rm = TRUE) * -1 ~ "Moderate Loss",
    Ftg_Rorelseresultat < 1.5 * median(Ftg_Rorelseresultat, na.rm = TRUE) * -1 ~ "High Loss",
    TRUE ~ NA_character_ ), # Handles cases where Ftg_Rorelseresultat might be NA
    
    Operating_Profit_Margin = ifelse(Ftg_Nettoomsattning == 0, NA_real_, 
                                     (Ftg_Rorelseresultat / Ftg_Nettoomsattning) * 100),
    Operating_Profit_Margin_category = case_when(
      is.na(Operating_Profit_Margin) ~ "Not Applicable",  # Handles division by zero and other NA cases
      Operating_Profit_Margin > 20 ~ "High Profitability, >20%",
      Operating_Profit_Margin > 5 & Operating_Profit_Margin <= 20 ~ "Moderate Profitability, 5% to 20%",
      #Operating_Profit_Margin > 1 & Operating_Profit_Margin <= 5 ~ "Low Profitability, ",
      Operating_Profit_Margin >= -5 & Operating_Profit_Margin <= 5 ~ "Breakeven, -5% to 5%",
      Operating_Profit_Margin < -5 ~ "Loss Making <-5%",
      TRUE ~ "Uncategorized" 
    )
  ) %>% 
  #  ggplot(aes(as.numeric(Operating_Profit_Margin))) + 
  #                 geom_histogram(bins=100) +
  # xlim(c(-100,100))
# select(Operating_Profit_Margin) %>% arrange(Operating_Profit_Margin)
  group_by(Profitability_Category) %>% 
  summarize(mean(Operating_Profit_Margin, na.rm = TRUE), 
            median(Operating_Profit_Margin, na.rm = TRUE),
            #median(Operating_Profit_Margin, na.rm = TRUE)*2,
            min(Operating_Profit_Margin, na.rm = TRUE), 
            max(Operating_Profit_Margin, na.rm = TRUE),
            n=n())

%>% mutate(
if Year<2014
SSYK = case_when(Ssyk1_majorlevel == 0 ~ "Military",
                        Ssyk1_majorlevel == 1 ~ "Managers",
                        Ssyk2_submajorlevel == 21 ~ "Science and engineering",
                        Ssyk2_submajorlevel == 22 ~ "Health care",
                        Ssyk2_submajorlevel == 23 ~ "Education",
                        Ssyk2_submajorlevel >= 24 & Ssyk2_submajorlevel < 30 ~ "Other professionals",
                        Ssyk1_majorlevel == 3 ~ "Associate professionals",
                        Ssyk1_majorlevel == 4 ~ "Admninistration and customer service",
                        Ssyk3_minorlevel == 513  ~ "Personal care",
                        str_starts(as.character(Ssyk3_minorlevel), "5") ~ "Service and shop sales",
                        Ssyk1_majorlevel == 6 ~ "Agriculture and forrestry",
                        Ssyk2_submajorlevel == 71 ~ "Building",
                        Ssyk2_submajorlevel > 71 & Ssyk2_submajorlevel < 80 ~ "Manufacturing",
                        Ssyk2_submajorlevel == 83 ~ "Transport",
                        Ssyk2_submajorlevel >= 80 & Ssyk2_submajorlevel < 83 | Ssyk2_submajorlevel >= 84 & Ssyk2_submajorlevel < 90 ~ "Mechanical manufacturing",
                        Ssyk2_submajorlevel == 91 ~ "Cleaners",
                        Ssyk2_submajorlevel > 91 ~ "Other elementary occupations",
                        TRUE ~ NA_character_),


else Year >=2014
SSYK = case_when(Ssyk1_majorlevel == 0 ~ "Military",
                        Ssyk1_majorlevel == 1 ~ "Managers",
                        Ssyk2_submajorlevel == 21 ~ "Science and engineering",
                        Ssyk2_submajorlevel == 22 ~ "Health care",
                        Ssyk2_submajorlevel == 23 ~ "Education",
                        Ssyk2_submajorlevel >= 24 & Ssyk2_submajorlevel < 30 ~ "Other professionals",
                        Ssyk1_majorlevel == 3 ~ "Associate professionals",
                        Ssyk1_majorlevel == 4 ~ "Admninistration and customer service",
                        Ssyk2_submajorlevel == 53 ~ "Personal care",
                        Ssyk2_submajorlevel > 50 & Ssyk2_submajorlevel < 54 | 
                        Ssyk2_submajorlevel >= 54 & Ssyk2_submajorlevel < 60 ~ "Service and shop sales",
                        Ssyk1_majorlevel == 6 ~ "Agriculture and forrestry",
                        Ssyk2_submajorlevel == 71 ~ "Building",
                        Ssyk2_submajorlevel > 71 & Ssyk2_submajorlevel < 80 ~ "Manufacturing",
                        Ssyk2_submajorlevel == 83 ~ "Transport",
                        Ssyk2_submajorlevel >= 80 & Ssyk2_submajorlevel < 83 | Ssyk2_submajorlevel >= 84 & Ssyk2_submajorlevel < 90 ~ "Mechanical manufacturing",
                        Ssyk2_submajorlevel == 91 ~ "Cleaners",
                        Ssyk2_submajorlevel > 91 ~ "Other elementary occupations",
                        TRUE ~ NA_character_)
)
  
  
  
  scb_2009 %>% 
    mutate(Operating_Profit_Margin = ifelse(
      "Ftg_Rorelseresultat" %in% names(.) && "Ftg_Nettoomsattning" %in% names(.),
      ifelse(Ftg_Nettoomsattning != 0, (Ftg_Rorelseresultat / Ftg_Nettoomsattning) * 100, NA_real_),
      NA_real_
    ),
    Operating_Profit_Margin_Category = case_when(
      Operating_Profit_Margin > 1~ "Profitable, >1%",
      Operating_Profit_Margin >= -1 & Operating_Profit_Margin <= 1 ~ "Breakeven, -1% to 1%",
      Operating_Profit_Margin < -1 ~ "Loss, <-1%",
      TRUE ~ NA_character_
    )
    ) %>% count(Operating_Profit_Margin_Category)
  
    scb_2009 %>% 
    mutate(
    Operating_Profit_Margin = ifelse(Ftg_Nettoomsattning != 0, (Ftg_Rorelseresultat / Ftg_Nettoomsattning) * 100, NA_real_)
  ) %>%
  mutate(
    Operating_Profit_Margin_Category = case_when(
      Operating_Profit_Margin > 1 ~ "Profitable, >1%",
      Operating_Profit_Margin >= -1 & Operating_Profit_Margin <= 1 ~ "Breakeven, -1% to 1%",
      Operating_Profit_Margin < -1 ~ "Loss, <-1%",
      TRUE ~ NA_character_
    )
  )%>% count(Operating_Profit_Margin_Category)
    
    
        scb_2009 %>% select(!c(Ftg_Rorelseresultat)) %>% 
  mutate(
    columns_exist = "Ftg_Rorelseresultat" %in% names(.) && "Ftg_Nettoomsattning" %in% names(.),
    # Temporarily include this to see the outcome of the check
    Operating_Profit_Margin = ifelse(columns_exist,
                                     ifelse(Ftg_Nettoomsattning != 0, (Ftg_Rorelseresultat / Ftg_Nettoomsattning) * 100, NA_real_),
                                     NA_real_),
    
        Operating_Profit_Margin_Category = case_when(
      Operating_Profit_Margin > 1 ~ "Profitable, >1%",
      Operating_Profit_Margin >= -1 & Operating_Profit_Margin <= 1 ~ "Breakeven, -1% to 1%",
      Operating_Profit_Margin < -1 ~ "Loss, <-1%",
      TRUE ~ NA_character_
  )) %>% select(Operating_Profit_Margin_Category, columns_exist)
    
      scb_2009 %>% 
          mutate(
    Operating_Profit_Margin = if("Ftg_Rorelseresultat" %in% names(.) && "Ftg_Nettoomsattning" %in% names(.), 
                                  ifelse(Ftg_Nettoomsattning != 0, (Ftg_Rorelseresultat / Ftg_Nettoomsattning) * 100, NA_real_),
                                  NA_real_)
  ) %>%
  mutate(
    Operating_Profit_Margin_Category = case_when(
      Operating_Profit_Margin > 1 ~ "Profitable, >1%",
      Operating_Profit_Margin >= -1 & Operating_Profit_Margin <= 1 ~ "Breakeven, -1% to 1%",
      Operating_Profit_Margin < -1 ~ "Loss, <-1%",
      TRUE ~ NA_character_
    )
  )%>% count(Operating_Profit_Margin_Category)
      
      # Check for column existence outside the row-wise mutate
if("Ftg_Rorelseresultat" %in% names(.) && "Ftg_Nettoomsattning" %in% names(.)) {
  dataset <- dataset %>%
    rowwise() %>%
    mutate(
      Operating_Profit_Margin = ifelse(Ftg_Nettoomsattning != 0, (Ftg_Rorelseresultat / Ftg_Nettoomsattning) * 100, NA_real_)
    ) %>%
    ungroup() # Remember to ungroup after rowwise operations
}

dataset <- dataset %>%
  mutate(
    Operating_Profit_Margin_Category = case_when(
      Operating_Profit_Margin > 1 ~ "Profitable, >1%",
      Operating_Profit_Margin >= -1 & Operating_Profit_Margin <= 1 ~ "Breakeven, -1% to 1%",
      Operating_Profit_Margin < -1 ~ "Loss, <-1%",
      TRUE ~ NA_character_
    )
  )
      
          Operating_Profit_Margin = ifelse("Ftg_Rorelseresultat" %in% names(.) && "Ftg_Nettoomsattning" %in% names(.) && Ftg_Nettoomsattning != 0, 
                                     (Ftg_Rorelseresultat / Ftg_Nettoomsattning) * 100, 
                                     NA_real_),
    Operating_Profit_Margin_Category = case_when(
        Operating_Profit_Margin > 1 ~ "Profitable, >1%",
        Operating_Profit_Margin >= -1 & Operating_Profit_Margin <= 1 ~ "Breakeven, -1% to 1%",
        Operating_Profit_Margin < -1 ~ "Loss, <-1%",
        TRUE ~ NA_character_
    ),
          
          
           scb_2009 %>%  #select(!c(Ftg_Rorelseresultat)) %>% 
    # Calculate Operating Profit Margin only when columns exist and Ftg_Nettoomsattning is not zero
  mutate(
    Operating_Profit_Margin = if ("Ftg_Nettoomsattning" %in% names(.) & Ftg_Nettoomsattning != 0) {
    Ftg_Rorelseresultat / Ftg_Nettoomsattning * 100
   } else {
      NA_real_
    }
    # Conditional categorization for Operating Profit Margin.
    # Operating_Profit_Margin_Category = case_when(
    #   is.na(Operating_Profit_Margin) ~ NA_character_,
    #   Operating_Profit_Margin > 1 ~ "Profitable, >1%",
    #   Operating_Profit_Margin >= -1 & Operating_Profit_Margin <= 1 ~ "Breakeven, -1% to 1%",
    #   Operating_Profit_Margin < -1 ~ "Loss, <-1%",
    #   TRUE ~ NA_character_
    # )
  ) %>% count(Operating_Profit_Margin)
          
          
          
                     scb_2009 %>%  select(!c(Ftg_Rorelseresultat)) %>% 
 mutate(
    Operating_Profit_Margin = case_when(
      "Ftg_Rorelseresultat" %in% names(.) & "Ftg_Nettoomsattning" %in% names(.) & Ftg_Nettoomsattning != 0 ~ Ftg_Rorelseresultat / Ftg_Nettoomsattning * 100,
      TRUE ~ NA_real_
    ),
    Operating_Profit_Margin_Category = case_when(
      is.na(Operating_Profit_Margin) ~ NA_character_,
      Operating_Profit_Margin > 1 ~ "Profitable, >1%",
      Operating_Profit_Margin >= -1 & Operating_Profit_Margin <= 1 ~ "Breakeven, -1% to 1%",
      Operating_Profit_Margin < -1 ~ "Loss, <-1%",
      TRUE ~ NA_character_
    )
  )%>% count(Operating_Profit_Margin_Category)
                     
                     
                     
scb_2009 %>%  select(!c(Ftg_Rorelseresultat)) %>% 
  mutate(
    # Check for column existence and assign NA_real_ if not exists
    Ftg_Rorelseresultat = if("Ftg_Rorelseresultat" %in% names(.)) Ftg_Rorelseresultat else NA_real_,
    Ftg_Nettoomsattning = if("Ftg_Nettoomsattning" %in% names(.)) Ftg_Nettoomsattning else NA_real_,
    # Calculate Operating Profit Margin based on the new conditions
    Operating_Profit_Margin = if_else(
      !is.na(Ftg_Rorelseresultat) & !is.na(Ftg_Nettoomsattning) & Ftg_Nettoomsattning != 0, 
      Ftg_Rorelseresultat / Ftg_Nettoomsattning * 100, 
      NA_real_
    ),
    # Categorize the Operating Profit Margin
    Operating_Profit_Margin_Category = case_when(
      is.na(Operating_Profit_Margin) ~ NA_character_,
      Operating_Profit_Margin > 1 ~ "Profitable, >1%",
      Operating_Profit_Margin >= -1 & Operating_Profit_Margin <= 1 ~ "Breakeven, -1% to 1%",
      Operating_Profit_Margin < -1 ~ "Loss, <-1%",
      TRUE ~ NA_character_
    )
  ) %>% 
  count(Operating_Profit_Margin_Category)
```


# 1 Raw data 

## 1.1 Simplify data

*Why:* To make data more manageable for further aggregation and analyses. 

*How:* 
- filter those without employment.  
- Create year variable from file name.  
- split data into those with and without HPI data and  
- create new variables based on SCB data.  
- Finally to save the year based files again.  

*What:* Population data per year from 1990 to 2021   



```{r}

library(tidyverse)
library(haven)
library(here)

# Load datasets
hpa <- read_csv(here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "HPI", "HPI clean", "EEB_hpb_clean_2023-10-16.csv")) %>% select(LopNr)

grunduppgifter <- 
haven::read_sas(here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306","Leverans1990_2022", "eeb_lev_grunduppgifter.sas7bdat")) %>% 
  select(LopNr, Kon, FodelseLand_EU28, FodelseAr)


# sni translation key
 translation_key_df <-
openxlsx::read.xlsx(here::here(str_glue("../../../HPI (DNR XXXXXX)/Data HPI registeruttag 2023/SCB/Leverans/Leverans_20240306/translation_SNI-versions.xlsx"))) %>% as_tibble() %>% 
   select(version, huvudgrupp_original, avdelning_samstammig, SNI_group) %>% 
# Adjust the translation key dataframe to include a uniform identifier for joining
  mutate(
    join_key = str_c(version, str_pad(huvudgrupp_original, width = 2, pad = "0"))
  )

# Prepare the main dataframe for joining by creating a similar join key


# data from tillväxtverket, another possibility could be skr
metropolitan_municipalities <- c("114", "123", "126", "127", "128", "136", "138", "139", "160", 
                                 "162", "163", "180", "181", "182", "183", "184", "186", "191", 
                                 "1230", "1231", "1262", "1280", "1281", "1402", "1480", "1481")

dense_municipalities <- c("115", "117", "120", "140", "187", "305", "330", "380", "381", "461", 
                          "480", "481", "483", "484", "486", "561", "562", "580", "581", "583", 
                          "584", "642", "643", "680", "682", "683", "686", "687", "760", "765", 
                          "780", "781", "880", "881", "882", "883", "884", "1060", "1080", "1082", 
                          "1233", "1261", "1263", "1272", "1275", "1282", "1277", "1282", "1283", 
                          "1285", "1286", "1287", "1290", "1292", "1380", 
                          "1382", "1401", "1407", "1440", "1441", "1472", "1482", "1484", "1485", 
                          "1486", "1487", "1488", "1489", "1490", "1492", "1493", "1494", "1495", 
                          "1496", "1497", "1498", "1499", "1715", "1761", "1780", "1781", "1782", 
                          "1784", "1785", "1862", "1880", "1881", "1883", "1884", "1907", "1960", 
                          "1961", "1980", "1981", "1982", "1983", "1984", "2062", "2080", "2081", 
                          "2085", "2104", "2180", "2181", "2262", "2280", "2281", "2380", "2523", "2580", "2581", 
                          "2582", "2583", "2584")

rural_municipalities <- c("125", "128", "188", "192", "319", "331", "360", "382", "428", "482", "488", "509", 
                          "512", "513", "560", "563", "580", "582", "586", "604", "617", "662", "665", 
                          "684", "685", "761", "763", "764", "767", "821", "834", "840", "860", "861", "862", "885", 
                          "980", "1081", "1083", "1214", "1256", "1257", "1260", "1264", "1265", 
                          "1266", "1267", "1270", "1273", "1276", "1278", "1284", "1291", "1293", "1315", 
                          "1381", "1383", "1384", "1415", "1419", "1421", "1427", "1430", "1435", 
                          "1438", "1439", "1442", "1443", "1444", "1445", "1446", "1447", "1452", 
                          "1460", "1461", "1462", "1463", "1465", "1466", "1491", "1470", "1471", "1473", 
                          "1730", "1737", "1760", "1762", "1763", "1764", "1765", "1766", "1783", "1814", 
                          "1860", "1861", "1863", "1864", "1882", "1885", "1904", "1962", "2021", 
                          "2023", "2026", "2029", "2031", 
                          "2034", "2039", "2061", "2082", "2083", "2084", "2101", "2121", "2132", 
                          "2161", "2182", "2183", "2184", "2260", "2282", "2283", "2284", "2303", 
                          "2305", "2309", "2313", "2321", "2326", "2361", "2401", "2403", "2404", 
                          "2409", "2417", "2418", "2421", "2422", "2425", "2460", "2462", "2463", 
                          "2480", "2481", "2482", "2505", "2506", "2510", "2513", "2514", "2518", 
                          "2521", "2560")





# Run function for conditional filter for syssälsätningsstatus

add_conditional_syssstat_filters <- function(data) {
  # Define the SyssStat* variables you're interested in
  columns_to_check <- c("SyssStatG", "SyssStat", "SyssStatJ", "SyssStat11", "SyssStat19")
  
  # Initialize a filter expression that is always true
  filter_expr <- expr(TRUE)
  
  # Dynamically update the filter expression based on column existence
  for (col in columns_to_check) {
    if (col %in% names(data)) {
      # Dynamically append the condition to the filter expression
      filter_expr <- expr(!!filter_expr & (!!sym(col) %in% c(1, 5)))
    }
  }
  
  # Apply the dynamic filter expression to the dataframe
  data %>% filter(!!filter_expr)
}


# Assuming 'hpa' dataframe is loaded with the LopNr of interest
interested_LopNr <- hpa %>% pull(LopNr)

# Construct the base path to the data directory
data_base_path <- here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306","Leverans1990_2022")

# Define the target folder for saving filtered CSV files
output_folder_with <- here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306", "with_hpi_lopnr", "2.filtered")

output_folder_without <- here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306", "without_hpi_lopnr", "2.filtered")

# Define the years of interest
years <- 1990:2021




# Generate file paths for each year
file_paths <- map(years, ~ file.path(data_base_path, str_glue("eeb_lev_{.x}.sas7bdat")))

# Process each file
map(file_paths, ~{
  file_path <- .x
    year <- str_extract(basename(file_path), "\\d{4}") # Extract the year from the file name

  data <- haven::read_sas(file_path) %>%
    left_join(grunduppgifter) %>% 
  mutate(
    Year = as.numeric(year), # Add the Year variable
    FodelseAr = as.numeric(FodelseAr),
    Age = Year - FodelseAr
  ) %>% 
  filter(Age > 17) %>%
  filter(LoneInk != 0 | !is.na(LoneInk)) %>% 
  filter(AntAns != 0 | !is.na(AntAns)) %>% # antal förvärvskällor
  add_conditional_syssstat_filters() %>% 
    # add join key for SNI
      mutate(
    AstSNI2007 = if("AstSNI2007" %in% names(.)) as.character(AstSNI2007) else NA_character_,
    AstSNI2002 = if("AstSNI2002" %in% names(.)) as.character(AstSNI2002) else NA_character_,
    AstSNI92 = if("AstSNI92" %in% names(.)) as.character(AstSNI92) else NA_character_) %>% 
    mutate(
    join_key = case_when(
      if("AstSNI2007" %in% names(.)) !is.na(AstSNI2007) ~ str_c("AstSNI2007", substr(AstSNI2007, 1, 2)),
      if("AstSNI2002" %in% names(.)) !is.na(AstSNI2002) ~ str_c("AstSNI2002", substr(AstSNI2002, 1, 2)),
      if("AstSNI92" %in% names(.)) !is.na(AstSNI92) ~ str_c("AstSNI92", substr(AstSNI92, 1, 2)),
      TRUE ~ NA_character_
    )) %>% 
      # Join the key, with SNI_group, avdelning_samstammig, SNI_group includes the categories that will be used in further analyses
     left_join(translation_key_df, by = "join_key") %>%  
      select(-join_key) %>% 
  mutate(
    AgeGroup = case_when(
      Age >= 18 & Age <= 35 ~ "18-35",
      Age > 35 & Age <= 50 ~ "36-50",
      Age > 50 & Age <= 65 ~ "51-65",
      TRUE ~ ">65"
    ),
    Sex = Kon,
    Place_of_origin = case_when(
  FodelseLand_EU28 == "Sverige" ~ "Sweden",
  FodelseLand_EU28 %in% c("EU28 utom Norden", "Europa utom EU28 och Norden", "Norden utom Sverige") ~ "Europe",
  FodelseLand_EU28 %in% c("Afrika", "Asien", "Nordamerika", "Oceanien", "Sydamerika", "Sovjetunionen") ~ "Outside Europe",
  FodelseLand_EU28 == "Okänt" ~ NA_character_,
  FodelseLand_EU28 == "" ~ NA_character_, 
  FodelseLand_EU28 == "Statslös" ~ NA_character_,
  TRUE ~ NA_character_
    ),
    Civil_status = case_when(
      Civil %in% c("G", "RP", "0", "2", "3", "7") ~ "Partner",  # Married or Registered Partner
      Civil %in% c("OG", "S", "Ä", "SP", "EP", "1", "4", "5", "8", "9") ~ "Single",  # Other categories
      TRUE ~ NA_character_  # Assign NA to cases that do not match any condition
    ),
  Kommun = as.numeric(Kommun),
    KommunSize = case_when(
    Kommun %in% metropolitan_municipalities ~ "Metropolitan municipalities",
    Kommun %in% dense_municipalities ~ "Dense municipalities",
    Kommun %in% rural_municipalities ~ "Rural municipalities",
    TRUE ~ NA_character_
  ),

  
    # EducationLevel = if ("Sun2000niva_old" %in% names(.)) {
    #     case_when(
    #       Sun2000niva_old %in% c("1", "2") ~ "Primary",
    #       Sun2000niva_old %in% c("3", "4") ~ "Secondary",
    #       Sun2000niva_old == "5" ~ "Tertiary <2 years",
    #       Sun2000niva_old %in% c("6", "7") ~ "Higher Education",
    #       TRUE ~ NA_character_
    #     )
    #   } else if ("Sun2020niva_Old" %in% names(.)) {
    #     case_when(
    #       Sun2020niva_Old %in% c("1", "2") ~ "Primary",
    #       Sun2020niva_Old %in% c("3", "4") ~ "Secondary",
    #       Sun2020niva_Old == "5" ~ "Tertiary <2 years",
    #       Sun2020niva_Old %in% c("6", "7") ~ "Higher Education",
    #       TRUE ~ NA_character_
    #     )
    #   } else NA_character_,
  
   # Dynamically assign edu based on the existence of Sun2020niva_old or Sun2000niva_old
    edu = if("Sun2020niva_Old" %in% names(.)) as.character(Sun2020niva_Old) else 
      if("Sun2000niva_Old" %in% names(.)) as.character(Sun2000niva_Old) else 
            if("Sun2000niva_old" %in% names(.)) as.character(Sun2000niva_old) else 
              NA_character_,
    # Since edu is now guaranteed to be assigned, we can directly categorize it
    EducationLevel = case_when(
      edu %in% c("1", "2") ~ "Primary",
      edu %in% c("3", "4") ~ "Secondary",
      #edu == "5" ~ "Tertiary <2 years",
      edu %in% c("5", "6", "7") ~ "Tertiary",
      TRUE ~ NA_character_
    ),
  
   Ownership_sector = if ("InstKod" %in% names(.)) {
      case_when(
        is.na(InstKod) ~ NA_character_,
        #"0000000000" ~ NA_character_,
        #"" ~ NA_character_,
        substr(InstKod, 3, 3) %in% c("1") ~ "Public Govermental",
        substr(InstKod, 3, 3) %in% c("2") ~ "Public Regional",
        substr(InstKod, 3, 3) %in% c("9") ~ "Private",
        TRUE ~ NA_character_
      )
    } else if ("InstKod6" %in% names(.)) {
      case_when(
        is.na(InstKod6) ~ NA_character_,
        substr(InstKod6, 4, 4) %in% c("1") ~ "Public Govermental",
        substr(InstKod6, 4, 4) %in% c("2") ~ "Public Regional",
        substr(InstKod6, 4, 4) %in% c("9") ~ "Private",
        TRUE ~ NA_character_
      )
    } else if ("InstKod7" %in% names(.)) {
      case_when(
         is.na(InstKod7) ~ NA_character_,
        substr(InstKod7, 4, 5) %in% c("10") ~ "Public Govermental",
        substr(InstKod7, 4, 5) %in% c("20", "30") ~ "Public Regional",
        substr(InstKod7, 4, 5) %in% c("41", "42", "50") ~ "Private",
        TRUE ~ NA_character_
      )
    } else if ("InstKod10" %in% names(.)) {
      case_when(
         is.na(InstKod10) ~ NA_character_,
        substr(InstKod10, 7, 8) %in% c("10") ~ "Public Govermental",
        substr(InstKod10, 7, 8) %in% c("20", "30") ~ "Public Regional",
        substr(InstKod10, 7, 8) %in% c("41", "42", "50") ~ "Private",
        TRUE ~ NA_character_
      )
    } else {
      NA_character_
    },
     Ssyk3_2012_J16_pop = if ("Ssyk3_2012_J16" %in% names(.)) {
     Ssyk3_2012_J16
   } else {
      NA_character_
    },
   Ssyk3_J16_pop = if("Ssyk3_J16" %in% names(.)) {
     Ssyk3_J16
   } else {
      NA_character_
    },
     Ssyk3_pop = if("Ssyk3" %in% names(.)) {
     Ssyk3
   } else {
      NA_character_
    },
  
  SsykAr = if("SsykAr" %in% names(.)) SsykAr else 
    if("SsykAr_J16" %in% names(.)) SsykAr_J16 else 
    NA_character_,
  # ifelse - nested in a way that each condition is only evaluated if the previous condition was not met
      Ssyk3_minorlevel = ifelse(
      is.na(SsykAr), NA_character_,
      ifelse(
        SsykAr > 2000 & SsykAr <= 2009 & "Ssyk3" %in% names(.), Ssyk3,
        ifelse(
          SsykAr > 2010 & SsykAr <= 2013 & "Ssyk3_J16" %in% names(.), Ssyk3_J16,
          ifelse(
            SsykAr > 2013 & "Ssyk3_2012_J16" %in% names(.), Ssyk3_2012_J16,
            NA_character_
          )
        )
      )
    ),
  Ssyk3_minorlevel = as.numeric(Ssyk3_minorlevel),
  # Ssyk3_minorlevel = if (length(grep("^Ssyk3", names(.))) > 0) {
  #     as.numeric(str_extract(.[[grep("^Ssyk3", names(.))[[1]]]], "\\d+"))
  #   } else NA_real_, # Using NA_real_ to explicitly denote numeric NA
  Ssyk2_submajorlevel = as.numeric(str_sub(Ssyk3_minorlevel, end = 2)),
  Ssyk1_majorlevel = as.numeric(str_sub(Ssyk3_minorlevel, end = 1)),
  
        SSYK =  if (length(grep("^Ssyk3", names(.))) > 0) {
 SSYK = case_when(
      # SSYK96, pre 2014
      SsykAr < 2014 & Ssyk1_majorlevel == 0 ~ "Military",
      SsykAr < 2014 & Ssyk1_majorlevel == 1 ~ "Managers",
      SsykAr < 2014 & Ssyk2_submajorlevel == 21 ~ "Science and engineering",
      SsykAr < 2014 & Ssyk2_submajorlevel == 22 ~ "Health care",
      SsykAr < 2014 & Ssyk2_submajorlevel == 23 ~ "Education",
      SsykAr < 2014 & Ssyk2_submajorlevel >= 24 & Ssyk2_submajorlevel < 30 ~ "Other professionals",
      SsykAr < 2014 & Ssyk1_majorlevel == 3 ~ "Associate professionals",
      SsykAr < 2014 & Ssyk1_majorlevel == 4 ~ "Administration and customer service",
      SsykAr < 2014 & Ssyk3_minorlevel == 513 ~ "Personal care",
      SsykAr < 2014 & str_starts(as.character(Ssyk3_minorlevel), "5") ~ "Service and shop sales",
      SsykAr < 2014 & Ssyk1_majorlevel == 6 ~ "Agriculture and forestry",
      SsykAr < 2014 & Ssyk2_submajorlevel == 71 ~ "Building",
      SsykAr < 2014 & Ssyk2_submajorlevel > 71 & Ssyk2_submajorlevel < 80 ~ "Manufacturing",
      SsykAr < 2014 & Ssyk2_submajorlevel == 83 ~ "Transport",
      SsykAr < 2014 & (Ssyk2_submajorlevel >= 80 & Ssyk2_submajorlevel < 83 | Ssyk2_submajorlevel >= 84 & Ssyk2_submajorlevel < 90) ~ "Mechanical manufacturing",
      SsykAr < 2014 & Ssyk2_submajorlevel == 91 ~ "Cleaners",
      SsykAr < 2014 & Ssyk2_submajorlevel > 91 ~ "Other elementary occupations",
      # SSYK2012, post 2013
      SsykAr >= 2014 & Ssyk1_majorlevel == 0 ~ "Military",
      SsykAr >= 2014 & Ssyk1_majorlevel == 1 ~ "Managers",
      SsykAr >= 2014 & Ssyk2_submajorlevel == 21 ~ "Science and engineering",
      SsykAr >= 2014 & Ssyk2_submajorlevel == 22 ~ "Health care",
      SsykAr >= 2014 & Ssyk2_submajorlevel == 23 ~ "Education",
      SsykAr >= 2014 & Ssyk2_submajorlevel >= 24 & Ssyk2_submajorlevel < 30 ~ "Other professionals",
      SsykAr >= 2014 & Ssyk1_majorlevel == 3 ~ "Associate professionals",
      SsykAr >= 2014 & Ssyk1_majorlevel == 4 ~ "Administration and customer service",
      SsykAr >= 2014 & Ssyk2_submajorlevel == 53 ~ "Personal care",
      SsykAr >= 2014 & (Ssyk2_submajorlevel > 50 & Ssyk2_submajorlevel < 54 | Ssyk2_submajorlevel >= 54 & Ssyk2_submajorlevel < 60) ~ "Service and shop sales",
      SsykAr >= 2014 & Ssyk1_majorlevel == 6 ~ "Agriculture and forestry",
      SsykAr >= 2014 & Ssyk2_submajorlevel == 71 ~ "Building",
      SsykAr >= 2014 & Ssyk2_submajorlevel > 71 & Ssyk2_submajorlevel < 80 ~ "Manufacturing",
      SsykAr >= 2014 & Ssyk2_submajorlevel == 83 ~ "Transport",
      SsykAr >= 2014 & (Ssyk2_submajorlevel >= 80 & Ssyk2_submajorlevel < 83 | Ssyk2_submajorlevel >= 84 & Ssyk2_submajorlevel < 90) ~ "Mechanical manufacturing",
      SsykAr >= 2014 & Ssyk2_submajorlevel == 91 ~ "Cleaners",
      SsykAr >= 2014 & Ssyk2_submajorlevel > 91 ~ "Other elementary occupations",
      TRUE ~ NA_character_
      )
    } else NA_character_
  ) %>% 
  mutate(
    IncomeLevel_CSFVI = case_when(
      CSFVI >= 2 * median(CSFVI, na.rm = TRUE) ~ "≥200%",
      CSFVI >= 1.2 * median(CSFVI, na.rm = TRUE) & CSFVI < 2 * median(CSFVI, na.rm = TRUE) ~ "120–199%",
      CSFVI >= 0.8 * median(CSFVI, na.rm = TRUE) & CSFVI < 1.2 * median(CSFVI, na.rm = TRUE) ~ "80–119%",
      CSFVI >= 0.6 * median(CSFVI, na.rm = TRUE) & CSFVI < 0.8 * median(CSFVI, na.rm = TRUE) ~ "60–79%",
      CSFVI < 0.6 * median(CSFVI, na.rm = TRUE) ~ "<60%",
      TRUE ~ NA_character_
    ),
    IncomeLevel = case_when(
      LoneInk >= 2 * median(LoneInk, na.rm = TRUE) ~ "≥200%",
      LoneInk >= 1.2 * median(LoneInk, na.rm = TRUE) & LoneInk < 2 * median(LoneInk, na.rm = TRUE) ~ "120–199%",
      LoneInk >= 0.8 * median(LoneInk, na.rm = TRUE) & LoneInk < 1.2 * median(LoneInk, na.rm = TRUE) ~ "80–119%",
      LoneInk >= 0.6 * median(LoneInk, na.rm = TRUE) & LoneInk < 0.8 * median(LoneInk, na.rm = TRUE) ~ "60–79%",
      LoneInk < 0.6 * median(LoneInk, na.rm = TRUE) ~ "<60%",
      TRUE ~ NA_character_
    )) %>% 
    # Löne eller företagarinkomst för huvudsaklig sysselsättning
           mutate(    
             Lon_Foretag = if ("LonFInk" %in% names(.)) {
      median_LoneFInk <- median(LonFInk, na.rm = TRUE)
      case_when(
        LonFInk >= 2 * median_LoneFInk ~ "≥200%",
        LonFInk >= 1.2 * median_LoneFInk & LonFInk < 2 * median_LoneFInk ~ "120–199%",
        LonFInk >= 0.8 * median_LoneFInk & LonFInk < 1.2 * median_LoneFInk ~ "80–119%",
        LonFInk >= 0.6 * median_LoneFInk & LonFInk < 0.8 * median_LoneFInk ~ "60–79%",
        LonFInk < 0.6 * median_LoneFInk ~ "<60%",
        TRUE ~ NA_character_
      )
    } else if ("ArsLonFInk" %in% names(.)) {
      median_ArsLonFInk <- median(ArsLonFInk, na.rm = TRUE)
      case_when(
        ArsLonFInk >= 2 * median_ArsLonFInk ~ "≥200%",
        ArsLonFInk >= 1.2 * median_ArsLonFInk & ArsLonFInk < 2 * median_ArsLonFInk ~ "120–199%",
        ArsLonFInk >= 0.8 * median_ArsLonFInk & ArsLonFInk < 1.2 * median_ArsLonFInk ~ "80–119%",
        ArsLonFInk >= 0.6 * median_ArsLonFInk & ArsLonFInk < 0.8 * median_ArsLonFInk ~ "60–79%",
        ArsLonFInk < 0.6 * median_ArsLonFInk ~ "<60%",
        TRUE ~ NA_character_
      )
    } else NA_character_,
    
    Operatingprofit_category = if ("Ftg_Rorelseresultat" %in% names(.)) {
  median_value <- median(Ftg_Rorelseresultat, na.rm = TRUE)
  case_when(
    Ftg_Rorelseresultat > 5 * median_value ~ ">500%",
    Ftg_Rorelseresultat >= 0 & Ftg_Rorelseresultat <= 5 * median_value ~ "0% to 500%",
    Ftg_Rorelseresultat < 0 & Ftg_Rorelseresultat > -5 * median_value ~ "-500% to 0%",
    Ftg_Rorelseresultat <= -5 * median_value ~ "<-500%",
    TRUE ~ NA_character_ 
  )
} else NA_character_, 
        # Check for column existence and assign NA_real_ if not exists
    Ftg_Rorelseresultat = if("Ftg_Rorelseresultat" %in% names(.)) Ftg_Rorelseresultat else NA_real_,
    Ftg_Nettoomsattning = if("Ftg_Nettoomsattning" %in% names(.)) Ftg_Nettoomsattning else NA_real_,
    
     Ftg_Nettoomsattning = if_else(Ftg_Nettoomsattning == 0, 0.1, Ftg_Nettoomsattning),
    # Calculate Operating Profit Margin based on the new conditions
    Operating_Profit_Margin = if_else(
      !is.na(Ftg_Rorelseresultat) & !is.na(Ftg_Nettoomsattning) & Ftg_Nettoomsattning != 0, 
      Ftg_Rorelseresultat / Ftg_Nettoomsattning * 100, 
      NA_real_
    ),
    # Categorize the Operating Profit Margin
    Operating_Profit_Margin_Category = case_when(
      Ftg_Nettoomsattning == 0 ~ "No Sales",
      is.na(Operating_Profit_Margin) ~ NA_character_,
      Operating_Profit_Margin > 5 ~ ">5%",
      Operating_Profit_Margin >= 0 & Operating_Profit_Margin <= 5 ~ "0% to 5%",
      Operating_Profit_Margin >= -5 & Operating_Profit_Margin < 0 ~ "-5% to 0%",
      Operating_Profit_Margin < -5 ~ "<-5%",
      TRUE ~ NA_character_
    ),
    
    Number_of_employees_Category = case_when(
    Ast_AntalSys >= 1 & Ast_AntalSys <= 9 ~ "1 to 9",
    Ast_AntalSys >= 10 & Ast_AntalSys <= 49 ~ "10 to 49",
    Ast_AntalSys >= 50 & Ast_AntalSys <= 249 ~ "50 to 249",
    Ast_AntalSys >= 250 ~ "≥250",
    TRUE ~ NA_character_
           ),
    Income_Sources_Category = case_when(
    AntAns == 1 ~ "1",
    AntAns >= 2 & AntAns <= 3 ~ "2 to 3",
    AntAns >= 4 ~ "≥4",
    TRUE ~ NA_character_ # For handling NA values
  ),
  Turnover_Rate_Category = case_when(
    PersOms_Harledd < 10 ~ "<10%",
    PersOms_Harledd >= 10 & PersOms_Harledd < 20 ~ "10% to 20%",
    PersOms_Harledd >= 20 ~ "≥20%",
    TRUE ~ NA_character_ # For handling NA or unexpected values
  )
      # Operating_Margin_Percent = ifelse(
      # all(c("Ftg_Rorelseresultat", "Ftg_Nettoomsattning") %in% names(.)) & Ftg_Nettoomsattning != 0,
      # (Ftg_Rorelseresultat / Ftg_Nettoomsattning) * 100,
      # NA_real_ # Assign NA if Net Sales is zero or columns do not exist
  #  )
           )
  
  gc()
  
  # Filter data for the interested LopNr and save
  filtered_data <- filter(data, LopNr %in% interested_LopNr)
  csv_path_filtered <-  file.path(output_folder_with, paste("with_HPI_data_categories", year, ".csv", sep="")) 
  write_csv(filtered_data, csv_path_filtered)
  
  # Filter out the interested LopNr and save
  excluded_data <- filter(data, !LopNr %in% interested_LopNr)
  csv_path_excluded <- csv_path_excluded <- file.path(output_folder_without, paste("without_HPI_data_categories", year, ".csv", sep="")) 
  write_csv(excluded_data, csv_path_excluded)
})






# Combine filtered data from all files into one dataframe, 
# you would read from the _filtered.csv files similarly to previous examples
filtered_csv_paths <- list.files(here::here(), pattern = "_filtered\\.csv$", full.names = TRUE)
combined_filtered_data <- map_dfr(filtered_csv_paths, read_csv, .id = "source")




```



## 1.2 Precarious employment 

*Why:* To get an marker of precarious employment, 

*How:* 
- Iterates over years 1991 to 2021 to load and process raw data, (Ssystat 1,5).  
- Combines all yearly data frames into a single data frame (all_data).  
- Filters another dataset (hpab) based on the presence of specific health-related parameters and previous selections, arranging and marking initial health parameter assessments for further analysis.  
- Processes work_duration_with and work_duration_without datasets to classify work durations into sequences and categories based on consecutive years worked and random sampling within year groups.  
- Writes processed data for "with HPI" and "without HPI" scenarios to CSV files.  
- Summarizes work duration data by year group and and category, calculating totals and percentages, and prepares data for output.  
- Writes summarized work duration data to CSV files for both "with HPI" and "without HPI" scenarios.  

*What:* Working in the same company for less than three years (two or one year).  






```{r}




library(dplyr)
library(haven)
library(here)



add_conditional_syssstat_filters <- function(data) {
  # Define the SyssStat* variables you're interested in
  columns_to_check <- c("SyssStatG", "SyssStat", "SyssStatJ", "SyssStat11", "SyssStat19")
  
  # Initialize a filter expression that is always true
  filter_expr <- expr(TRUE)
  
  # Dynamically update the filter expression based on column existence
  for (col in columns_to_check) {
    if (col %in% names(data)) {
      # Dynamically append the condition to the filter expression
      filter_expr <- expr(!!filter_expr & (!!sym(col) %in% c(1, 5)))
    }
  }
    # Apply the dynamic filter expression to the dataframe
  data %>% filter(!!filter_expr)
 }
# Define the base path to the datasets
base_path <- here("..", "..", "..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306", "Leverans1990_2022")

# Initialize an empty list to store data frames
data_list <- list()

years <- 1991:2021


for (year in years) {
  file_name <- sprintf("eeb_lev_%d.sas7bdat", year)
  full_path <- file.path(base_path, file_name)
  
  # Load the dataset and add the year column
  temp_data <- read_sas(full_path) %>%
    add_conditional_syssstat_filters() %>% 
    select(LopNr, LopNr_ArbstId) %>% 
    mutate(year = year)
  
  # Append the processed data to the list
  data_list[[as.character(year)]] <- temp_data
    rm(temp_data) # Explicitly remove the temporary data frame
  gc() # Manually invoke garbage collection
  
  # The temp_data variable will be overwritten in the next iteration, which helps with memory management
}

# Combine all data frames into a single data frame
all_data <- bind_rows(data_list)




hpa <- read_csv(here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "HPI", "HPI clean", "EEB_hpb_clean_2023-10-16.csv")) %>% select(LopNr, Year) %>% mutate(selected = 1)
# Group by person_id and LopNr_ArbstId, then summarise to find work duration


work_duration_with <- 
  all_data %>% 
  left_join(hpa  %>% distinct(LopNr, .keep_all = TRUE), 
            by = c("LopNr" = "LopNr"),
            relationship = "many-to-one") %>% 
  filter(selected==1)

work_duration_without <-  all_data %>% left_join(hpa %>% distinct(LopNr, .keep_all = TRUE), by = c("LopNr" = "LopNr")) %>% 
  filter(is.na(selected))


hpab <-
read_csv(here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "HPI", "HPI clean", "EEB_hpb_clean_2023-10-16.csv")) %>% 
   filter(rowSums(!is.na(select(., EkB_rel_VO2, Astrand_rel_VO2, HeightCM, WeightKG, BloodPressureSystolic, BloodPressureDiastolic))) >= 2,
         rowSums(!is.na(select(., ExerciseAnswer, TobaccoSmoking, Diet, Health, StressOverall, SymptomBackNeck))) >= 2) %>% 
     arrange(LopNr, Performed) %>% 
  mutate(hpa_number = row_number(), 
         test_count = n(), .by = LopNr) %>% 
    # take the first hpi tests
  filter(hpa_number == 1) %>% 
   select(LopNr, Year) %>% 
   mutate(selected = 1)

  # mutate(work_duration_category = case_when(
  #   duration >= 10 ~ "More than 10 years",
  #   duration >= 5 ~ "5 years",
  #   duration >= 3 ~ "3 years",
  #   duration  < 3 ~ "Less than 3 years",
  #   TRUE ~ NA_character_
  # ))


duration_seq_with <-
work_duration_with %>%
  filter(!is.na(LopNr_ArbstId)) %>%
  arrange(LopNr, year) %>%
  group_by(LopNr) %>%
  mutate(
    # Identify when LopNr_ArbstId changes
    change = LopNr_ArbstId != lag(LopNr_ArbstId),
    # Create a group for consecutive sequences
    grp = cumsum(change | is.na(change)) # Account for the first row in each group
  ) %>%
  # Within each LopNr and sequence group, number the rows starting from 0
  group_by(LopNr, grp) %>%
  mutate(consecutive_years = row_number() - 1) %>%
  ungroup() %>% 
  mutate(consecutive_years_category = case_when(
    consecutive_years >= 3 ~ ">=3 years",
    consecutive_years  < 3 ~ "<3 years",
    TRUE ~ NA_character_
  ),
   year_group = case_when(
      year >= 1995 & year <= 1999 ~ "1995-1999",
      year >= 2000 & year <= 2004 ~ "2000-2004",
      year >= 2005 & year <= 2009 ~ "2005-2009",
      year >= 2010 & year <= 2014 ~ "2010-2014",
      year >= 2015 & year <= 2019 ~ "2015-2019",
      year >= 2020 & year <= 2021 ~ "2020-2021",
      TRUE ~ "Other")
  ) %>% 
  select(!c(Year, selected)) %>% 
  left_join(hpab, by = c("LopNr" = "LopNr", "year" = "Year")) %>% 
  filter(selected==1) %>% 
    group_by(LopNr, year_group) %>%
  # Randomly select one entry per LopNr within each year group
  sample_n(size = 1) %>%
  ungroup()



set.seed(123) 
duration_seq_without <-
work_duration_without %>%
  filter(!is.na(LopNr_ArbstId)) %>%
  arrange(LopNr, year) %>%
  group_by(LopNr) %>%
  mutate(
    # Identify when LopNr_ArbstId changes
    change = LopNr_ArbstId != lag(LopNr_ArbstId),
    # Create a group for consecutive sequences
    grp = cumsum(change | is.na(change)) # Account for the first row in each group
  ) %>%
  # Within each LopNr and sequence group, number the rows starting from 0
  group_by(LopNr, grp) %>%
  mutate(consecutive_years = row_number() - 1) %>%
  ungroup() %>% 
  mutate(consecutive_years_category = case_when(
    consecutive_years >= 3 ~ ">=3 years",
    consecutive_years  < 3 ~ "<3 years",
    TRUE ~ NA_character_
  ),
   year_group = case_when(
      year >= 1995 & year <= 1999 ~ "1995-1999",
      year >= 2000 & year <= 2004 ~ "2000-2004",
      year >= 2005 & year <= 2009 ~ "2005-2009",
      year >= 2010 & year <= 2014 ~ "2010-2014",
      year >= 2015 & year <= 2019 ~ "2015-2019",
      year >= 2020 & year <= 2021 ~ "2020-2021",
      TRUE ~ "Other")
  )%>% 
    group_by(LopNr, year_group) %>%
  # Randomly select one entry per LopNr within each year group
  sample_n(size = 1) %>%
  ungroup()


write_csv(duration_seq_with, here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306", "with_hpi_lopnr", "5.work_duration", "workduration_with.csv"))

write_csv(duration_seq_without, here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306", "with_hpi_lopnr", "5.work_duration", "workduration_without.csv"))

duration_seq_with_sum<-
duration_seq_with %>% 
  group_by(year_group, consecutive_years_category) %>% 
   summarise(n = n(), .groups = "drop") %>%
  # Calculate the total count for each year_group
  group_by(year_group) %>%
  mutate(total = sum(n)) %>%
  # Calculate percentage
  mutate(percentage = (n / total) * 100) %>%
  ungroup() %>% 
        mutate(YearGroup = year_group,
             data = "with_HPI") %>% 
  filter(year_group!="Other")


duration_seq_without_sum<-
duration_seq_without %>% 
  group_by(year_group, consecutive_years_category) %>% 
   summarise(n = n(), .groups = "drop") %>%
  # Calculate the total count for each year_group
  group_by(year_group) %>%
  mutate(total = sum(n)) %>%
  # Calculate percentage
  mutate(percentage = (n / total) * 100) %>%
  ungroup() %>% 
        mutate(YearGroup = year_group,
             data = "without_HPI") %>% 
  filter(year_group!="Other")


write_csv(duration_seq_with_sum, here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306", "with_hpi_lopnr", "5.work_duration", "workduration_with_summarized.csv"))

write_csv(duration_seq_without_sum, here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306", "with_hpi_lopnr", "5.work_duration", "workduration_without_summarized.csv"))

```





# 2 Filtered data 

## 2.1 Extract variables

*Why:* Extract variables for those who performes an HPA for descriptive tables with only HPI data, income data is used to select the study sample.

*How:* 
- read in filtered data of those with HPI data
- go trough all datasets and select variables that has not been in earlier scb data.
- Finally to save the selected data as one dataset

*What:* Among other variables:  
LoneInk	Kontant bruttolön m.m.
LonFInk	Löne- eller företagarinkomst
CSFVI	Sammanräknad förvärvsinkomst -  en individs arbetsinkomster (före skatter och transfereringar, men inklusive inkomster från sociala försäkringar knutna till att arbeta, så som arbetslöshetsersättning, sjukpenning,
etc.)



```{r}

library(here)
library(readr)
library(dplyr)

input_folder <- here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306", "with_hpi_lopnr", "2.filtered")
output_folder <- here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306", "with_hpi_lopnr", "6.organization_variables")

hpa <- read_csv(here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "HPI", "HPI clean", "EEB_hpb_clean_2023-10-16.csv")) %>% select(LopNr, Year, Performed) 

data_list <- list()
 years <- 1990:2021


for (year in years) {
  file_name <- sprintf("with_HPI_data_categories%d.csv", year)
  full_path <- file.path(input_folder, file_name)
  
  # Load the dataset
  temp_data <- read_csv(full_path, show_col_types = FALSE)
  
  # Check if 'ArsLonFInk' exists and rename it to 'LonFInk' if it does
  if("ArsLonFInk" %in% names(temp_data)) {
    temp_data <- temp_data %>% rename(LonFInk = ArsLonFInk)
  }
  

  temp_data <- temp_data %>%
    mutate(year = year) %>%
    select(LopNr, year, 
# individual level/sociodemographics
Place_of_origin, Civil_status, EducationLevel, Ssyk3_minorlevel, SSYK, IncomeLevel, KommunSize, LoneInk, Income_Sources_Category,
# worklife organisational
Ownership_sector, Number_of_employees_Category, Turnover_Rate_Category, Operating_Profit_Margin, Operating_Profit_Margin_Category, Operatingprofit_category, SNI_group, SsykAr,

Ssyk3_J16_pop, Ssyk3_pop, Ssyk3_2012_J16_pop
           ) %>% 
    distinct(LopNr, year, .keep_all = TRUE)
  
    # Check for parsing issues
  # parsing_problems <- problems(temp_data)
  # if (nrow(parsing_problems) > 0) {
  #   print(paste("Year:", year, "- Found", nrow(parsing_problems), "parsing issues."))
  #   print(head(parsing_problems))
  # }
  # check for problems reading files
  print(paste("Reading file for year:", year, "with", nrow(temp_data), "rows."))

  
  # Append the processed data to the list
  data_list[[as.character(year)]] <- temp_data
}

# Combine all data frames into a single data frame
all_data <- bind_rows(data_list)

all_data %>% filter(year==2021) %>% print(n=100)

# Joining all_data with hpa dataset
final_data <- hpa %>% left_join(all_data, by = c("LopNr", "Year" = "year")) %>% 
  mutate(n=n(), .by = c(LopNr, Performed)) %>% filter(n==1) 



# Optionally, write the final_data to a file in the output_folder
write_csv(final_data, file.path(output_folder, "organization_data.csv"))




temp_ <- read_csv( here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306", "with_hpi_lopnr", "2.filtered", "with_HPI_data_categories2020.csv"), show_col_types = FALSE)

# Check for parsing problems
parsing_issues <- problems(data_list)
if(nrow(parsing_issues) > 0) {
  print(parsing_issues)
}



# # Check for duplicates in `all_data`
# duplicates_all_data <- all_data %>%
#   count(LopNr, year) %>%
#   filter(n > 1)
# final_data %>% filter(is.na(LoneInk))
# all_data %>% filter(LopNr==234487 | LopNr==246693) %>% print(n=100)
# # Check for duplicates in `hpa`
# duplicates_hpa <- hpa %>%
#   count(LopNr, Year) %>%
#   filter(n > 1)
# 
# # View the results
# print("Duplicates in all_data:")
# print(duplicates_all_data)
# 
# print("Duplicates in hpa:")
# print(duplicates_hpa)

```

## 2.2 Sumarizing data without HPI data

*Why:* To be able to compare population data and HPI data

*How:*   
- Combine Employment Data: Merge five datasets excluding HPI data to form a comprehensive employment dataset with filtered datasets.
- Filter and Sample: Apply filters for specific employment statuses (1 or 5) and randomly select one record per LopNr within each 5-year group to ensure representation without duplication.
- Enrich Data: Augment the dataset with demographic information from scb_grunduppgifter based on gender, age, and birth country, focusing on individuals over 18.
- Categorize and Summarize: Create variables for age groups and median income percentages, summarizing data to highlight counts, gender distribution, age groups, and income levels for each 5-year period.
- Iterate and Output: Process all specified 5-year periods, saving summarized data for further analysis and employing memory management strategies between iterations.
 

*What:* Summarize data into 5 year groups for those without HPI data





```{r}




data_base_path <- here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306","without_hpi_lopnr")

set_seed <- function(data, seed = 123) {
  set.seed(seed)
  return(data)
}


process_datasets <- function(year_group, file_paths) {
  # 1. Read in the datasets
  datasets <- map_df(file_paths, ~read_csv(.x) %>%
                       select(
                         LopNr, 
                         # individual level/sociodemographics
                         AgeGroup, Sex, 
                         
                         Place_of_origin, Civil_status, EducationLevel, SSYK, IncomeLevel, KommunSize, Income_Sources_Category,
                         # worklife organisational
                        Ownership_sector, Number_of_employees_Category, Turnover_Rate_Category, Operating_Profit_Margin_Category, Operatingprofit_category, SNI_group
                       )) 
  
  # 3. Randomly sample one of each LopNr
  sampled_data <-  datasets %>%
    group_by(LopNr) %>%
    set_seed(seed = 123) %>%
    sample_n(1) %>%
    ungroup()
  
  # 4. Summarize data
  
  #  variable lists
  categorical_vars <- c(
    "AgeGroup", 
    "Sex", 
    "Place_of_origin", 
    "Civil_status", 
    "EducationLevel", 
    "SSYK", 
    "Income_Sources_Category", 
    "IncomeLevel", 
    "KommunSize",
    "Ownership_sector", 
    "Number_of_employees_Category",
    "Turnover_Rate_Category", 
    "Operatingprofit_category",
    "Operating_Profit_Margin_Category", 
    "SNI_group"
  )
continuous_vars <- c("Turnover_Rate_Percent") #, "Operating_Margin_Percent"
  
calculate_percentages <- function(df, vars, group_var = NULL) {
  if (!is.null(group_var) && group_var %in% names(df)) {
    df %>%
      mutate(across(all_of(vars), as.character)) %>% # Ensure vars are characters
      select(.data[[group_var]], all_of(vars)) %>%
      pivot_longer(cols = -all_of(group_var), names_to = "Variable", values_to = "Categories") %>%
      group_by(.data[[group_var]], Variable, Categories) %>%
      summarize(n = n(), .groups = "drop_last") %>%
      group_by(.data[[group_var]], Variable) %>%
      mutate(Value = 100 * (n / sum(n))) %>%
      ungroup() %>%
      select(-sum) %>%
      rename(Value = Percent) # Ensure unified "Value" column for output
  } else {
    df %>%
      mutate(across(all_of(vars), as.character)) %>% # Ensure vars are characters
      pivot_longer(cols = all_of(vars), names_to = "Variable", values_to = "Categories") %>%
      count(Variable, Categories) %>%
      group_by(Variable) %>%
      mutate(Value = 100 * n / sum(n)) %>%
      ungroup()
  }
}


calculate_means <-  function(df, vars) {
  summaries <- lapply(vars, function(var) {
    total_count <- nrow(df)
    na_count <- sum(is.na(df[[var]]))
    non_na_count <- total_count - na_count
    mean_val <- mean(df[[var]], na.rm = TRUE)
    
    data.frame(
      Variable = rep(var, 2),
      #Categories = "", # Empty to match the desired format
      n = c(non_na_count, na_count), # Count of non-NA values for mean, and NA count
      Value = c(mean_val, NA), # Mean for non-NA, NA for the NA count row
      Categories = c("Mean", "NA Count") # Distinguishing between mean value and NA count
    ) %>% as_tibble()
  })
  
  do.call(rbind, summaries)
}



summary_data <- bind_rows(
  calculate_percentages(sampled_data, categorical_vars),
  calculate_means(sampled_data, continuous_vars)
)
  
  # 5. Save the dataset
path_output <- here::here(str_glue("../../../HPI (DNR XXXXXX)/Data HPI registeruttag 2023/SCB/Leverans/Leverans_20240306/without_hpi_lopnr/3.summarized/Summary_witout_hpi_data_{year_group}.csv"))


  write_csv(summary_data, path_output)
  
  # 6. Clear memory
  rm(list = c("datasets", "filtered_data", "sampled_data", "enriched_data", "final_data", "summary_data"))
  gc()
}

# Example usage
# Define file paths for one of the five-year groups (adjust paths accordingly)
file_paths_1995_1999 <- c(here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306","without_hpi_lopnr", "2.filtered", "without_HPI_data_categories1995.csv"), 
                          here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306","without_hpi_lopnr", "2.filtered", "without_HPI_data_categories1996.csv"), 
                          here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306","without_hpi_lopnr", "2.filtered", "without_HPI_data_categories1997.csv"), 
                          here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306","without_hpi_lopnr", "2.filtered", "without_HPI_data_categories1998.csv"), 
                          here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306","without_hpi_lopnr", "2.filtered", "without_HPI_data_categories1999.csv"))

generate_file_paths <- function(start_year, end_year, base_path) {
  years <- start_year:end_year
  file_paths <- lapply(years, function(year) {
    paste0(base_path, "/without_HPI_data_categories", year, ".csv")
  })
  return(unlist(file_paths))
}

# Assuming base_path is defined like this (adjust according to your directories):
base_path <- here::here("..", "..", "..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306", "without_hpi_lopnr", "2.filtered")



# Generate file paths for the period 2000-2004 as an example
file_paths_1995_1999 <- generate_file_paths(1995, 1999, base_path)
file_paths_2000_2004 <- generate_file_paths(2000, 2004, base_path)
file_paths_2005_2009 <- generate_file_paths(2005, 2009, base_path)
file_paths_2010_2014 <- generate_file_paths(2010, 2014, base_path)
file_paths_2015_2019 <- generate_file_paths(2015, 2019, base_path)
file_paths_2020_2021 <- generate_file_paths(2020, 2021, base_path)


# Call the function
process_datasets("1995-1999", file_paths_1995_1999)
process_datasets("2000-2004", file_paths_2000_2004)
process_datasets("2005-2009", file_paths_2005_2009)
process_datasets("2010-2014", file_paths_2010_2014)
process_datasets("2015-2019", file_paths_2015_2019)
process_datasets("2020-2021", file_paths_2020_2021)


```


## 2.3 Sumarizing data with HPI data

*Why:* To be able to compare population data and HPI data

*How:*   
- Combine Employment Data: Merge five datasets excluding HPI data to form a comprehensive employment dataset with filtered datasets.
- Filter and Sample: Apply filters for specific employment statuses (1 or 5) and randomly select one record per LopNr within each 5-year group to ensure representation without duplication.
- Enrich Data: Augment the dataset with demographic information from scb_grunduppgifter based on gender, age, and birth country, focusing on individuals over 18.
- Categorize and Summarize: Create variables for age groups and median income percentages, summarizing data to highlight counts, gender distribution, age groups, and income levels for each 5-year period.
- Iterate and Output: Process all specified 5-year periods, saving summarized data for further analysis and employing memory management strategies between iterations.
 

*What:* Summarize data into 5 year groups for those with HPI data



```{r}

# scb_withhpi1996<-
# read_csv(here::here("..", "..", "..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306", "with_hpi_lopnr", "2.filtered", "with_HPI_data_categories1996.csv"))
# 
# 
# data_base_path <- here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306","with_hpi_lopnr")


process_datasets <- function(year_group, file_paths) {
  # 1. Read in the datasets
 datasets <- map_df(file_paths, ~read_csv(.x) %>%
                      select(
                        LopNr, AgeGroup, Sex, Year, 
                                                 # individual level/sociodemographics
                         Place_of_origin, Civil_status, EducationLevel, Ssyk3_minorlevel, SSYK, IncomeLevel, KommunSize, Income_Sources_Category,
                         # worklife organisational
                        Ownership_sector, Number_of_employees_Category, Turnover_Rate_Category, Operating_Profit_Margin_Category, Operatingprofit_category, SNI_group,
                             )) 
 
 hpa <- read_csv(here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "HPI", "HPI clean", "EEB_hpb_clean_2023-10-16.csv")) %>% 
   filter(rowSums(!is.na(select(., EkB_rel_VO2, Astrand_rel_VO2, HeightCM, WeightKG, BloodPressureSystolic, BloodPressureDiastolic))) >= 2,
         rowSums(!is.na(select(., ExerciseAnswer, TobaccoSmoking, Diet, Health, StressOverall, SymptomBackNeck))) >= 2) %>% 
     arrange(LopNr, Performed) %>% 
  mutate(hpa_number = row_number(), 
         test_count = n(), .by = LopNr) %>% 
    # take the first hpi tests
  filter(hpa_number == 1) %>% 
   select(LopNr, Year) %>% 
   mutate(selected = 1)
  
  # 3. Randomly sample one of each LopNr
  sampled_data <-  
    datasets %>% 
    # join by lopnr and Year with HPI data
    left_join(hpa, by = join_by(LopNr, Year)) %>% 
    # filter those that has an HPI test
    filter(selected==1)  #%>% 
   # distinct(LopNr, Year, .keep_all = TRUE)
  
  

  # 4. Summarize data
  
  #  variable lists
    categorical_vars <- c(
    "AgeGroup", 
    "Sex", 
    "Place_of_origin", 
    "Civil_status", 
    "EducationLevel", 
    "SSYK", 
    "Income_Sources_Category", 
    "IncomeLevel", 
    "KommunSize",
    "Ownership_sector", 
    "Number_of_employees_Category",
    "Turnover_Rate_Category", 
    "Operatingprofit_category",
    "Operating_Profit_Margin_Category", 
    "SNI_group"
)
continuous_vars <- c("Turnover_Rate_Percent") #, "Operating_Margin_Percent"
  
calculate_percentages <- function(df, vars, group_var = NULL) {
  if (!is.null(group_var) && group_var %in% names(df)) {
    df %>%
      mutate(across(all_of(vars), as.character)) %>% # Ensure vars are characters
      select(.data[[group_var]], all_of(vars)) %>%
      pivot_longer(cols = -all_of(group_var), names_to = "Variable", values_to = "Categories") %>%
      group_by(.data[[group_var]], Variable, Categories) %>%
      summarize(n = n(), .groups = "drop_last") %>%
      group_by(.data[[group_var]], Variable) %>%
      mutate(Value = 100 * (n / sum(n))) %>%
      ungroup() %>%
      select(-sum) %>%
      rename(Value = Percent) # Ensure unified "Value" column for output
  } else {
    df %>%
      mutate(across(all_of(vars), as.character)) %>% # Ensure vars are characters
      pivot_longer(cols = all_of(vars), names_to = "Variable", values_to = "Categories") %>%
      count(Variable, Categories) %>%
      group_by(Variable) %>%
      mutate(Value = 100 * n / sum(n)) %>%
      ungroup()
  }
}


calculate_means <-  function(df, vars) {
  summaries <- lapply(vars, function(var) {
    total_count <- nrow(df)
    na_count <- sum(is.na(df[[var]]))
    non_na_count <- total_count - na_count
    mean_val <- mean(df[[var]], na.rm = TRUE)
    
    data.frame(
      Variable = rep(var, 2),
      #Categories = "", # Empty to match the desired format
      n = c(non_na_count, na_count), # Count of non-NA values for mean, and NA count
      Value = c(mean_val, NA), # Mean for non-NA, NA for the NA count row
      Categories = c("Mean", "NA Count") # Distinguishing between mean value and NA count
    ) %>% as_tibble()
  })
  
  do.call(rbind, summaries)
}



summary_data <- bind_rows(
  calculate_percentages(sampled_data, categorical_vars),
  calculate_means(sampled_data, continuous_vars)
)
  
  # 5. Save the dataset
path_output <- here::here(str_glue("../../../HPI (DNR XXXXXX)/Data HPI registeruttag 2023/SCB/Leverans/Leverans_20240306/with_hpi_lopnr/3.summarized/Summary_with_hpi_data_{year_group}.csv"))


  write_csv(summary_data, path_output)
  
  # 6. Clear memory
  rm(list = c("datasets", "sampled_data", "summary_data"))
  gc()
}

# Example usage
# Define file paths for one of the five-year groups (adjust paths accordingly)

generate_file_paths <- function(start_year, end_year, base_path) {
  years <- start_year:end_year
  file_paths <- lapply(years, function(year) {
    paste0(base_path, "/with_HPI_data_categories", year, ".csv")
  })
  return(unlist(file_paths))
}

# Assuming base_path is defined like this (adjust according to your directories):
base_path <- here::here("..", "..", "..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306", "with_hpi_lopnr", "2.filtered")



# Generate file paths for the period 2000-2004 as an example
file_paths_1995_1999 <- generate_file_paths(1995, 1999, base_path)
file_paths_2000_2004 <- generate_file_paths(2000, 2004, base_path)
file_paths_2005_2009 <- generate_file_paths(2005, 2009, base_path)
file_paths_2010_2014 <- generate_file_paths(2010, 2014, base_path)
file_paths_2015_2019 <- generate_file_paths(2015, 2019, base_path)
file_paths_2020_2021 <- generate_file_paths(2020, 2021, base_path)


# Call the function
process_datasets("1995-1999", file_paths_1995_1999)
process_datasets("2000-2004", file_paths_2000_2004)
process_datasets("2005-2009", file_paths_2005_2009)
process_datasets("2010-2014", file_paths_2010_2014)
process_datasets("2015-2019", file_paths_2015_2019)
process_datasets("2020-2021", file_paths_2020_2021)




```

## 2.4 Over and underreached without HPI data

```{r}







calculate_percentages_for_groups <- function(df, group_vars) {
  df %>%
    select(all_of(group_vars)) %>%
    group_by(across(all_of(group_vars))) %>%
    summarize(n = n(), .groups = "drop") %>%
    mutate(Percent = 100 * n / sum(n))
}



process_datasets <- function(year_group, file_paths) {
  # Load the necessary libraries
  library(dplyr)
  library(purrr)

  # 1. Read in the datasets and select relevant columns
  datasets <- map_df(file_paths, ~read_csv(.x) %>%
                      select(LopNr, AgeGroup, Sex, 
                             EducationLevel, Ssyk_majorlevel, InstitutionCategory))
  
  # 2. Set seed for reproducibility
  set.seed(123)
  
  # 3. Randomly sample one of each LopNr
  sampled_data <- datasets %>%
    group_by(LopNr) %>%
    sample_n(1) %>%
    ungroup()

  # 4. Calculate percentages for groups
  group_vars <- c("AgeGroup", "Sex", "EducationLevel", "Ssyk_majorlevel", "InstitutionCategory")
  percentage_df <- calculate_percentages_for_groups(sampled_data, group_vars)

  # 5. Save the dataset
  path_output <- here("../../../HPI (DNR XXXXXX)/Data HPI registeruttag 2023/SCB/Leverans/Leverans_20240306/without_hpi_lopnr/4.summarized_within_groups", str_glue("{year_group}.csv"))
  write_csv(percentage_df, path_output)
  
  # 6. Clear memory
  rm(list = c("datasets", "sampled_data", "percentage_df"))
  gc()
}



generate_file_paths <- function(start_year, end_year, base_path) {
  years <- start_year:end_year
  file_paths <- lapply(years, function(year) {
    paste0(base_path, "/without_HPI_data_categories", year, ".csv")
  })
  return(unlist(file_paths))
}

# Assuming base_path is defined like this (adjust according to your directories):
base_path <- here::here("..", "..", "..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306",  "without_hpi_lopnr","2.filtered")



# Generate file paths for the period 2000-2004 as an example
file_paths_2016_2021 <- generate_file_paths(2015, 2021, base_path)


# Call the function
process_datasets("2017-2021", file_paths_2016_2021)




```

## 2.5 Over and underreached with HPI data

```{r}







calculate_percentages_for_groups <- function(df, group_vars) {
  df %>%
    select(all_of(group_vars)) %>%
    group_by(across(all_of(group_vars))) %>%
    summarize(n = n(), .groups = "drop") %>%
    mutate(Percent = 100 * n / sum(n))
}



process_datasets <- function(year_group, file_paths) {
  # Load the necessary libraries
  library(dplyr)
  library(purrr)

  # 1. Read in the datasets and select relevant columns
  datasets <- map_df(file_paths, ~read_csv(.x) %>%
                      select(LopNr, AgeGroup, Sex, 
                             EducationLevel, Ssyk_majorlevel, InstitutionCategory))
  
  # 2. Set seed for reproducibility
  set.seed(123)
  
  # 3. Randomly sample one of each LopNr
  sampled_data <- datasets %>%
    group_by(LopNr) %>%
    sample_n(1) %>%
    ungroup()

  # 4. Calculate percentages for groups
  group_vars <- c("AgeGroup", "Sex", "EducationLevel", "Ssyk_majorlevel", "InstitutionCategory")
  percentage_df <- calculate_percentages_for_groups(sampled_data, group_vars)

  # 5. Save the dataset
  path_output <- here("../../../HPI (DNR XXXXXX)/Data HPI registeruttag 2023/SCB/Leverans/Leverans_20240306/with_hpi_lopnr/4.summarized_within_groups", str_glue("{year_group}.csv"))
  write_csv(percentage_df, path_output)
  
  # 6. Clear memory
  rm(list = c("datasets", "sampled_data", "percentage_df"))
  gc()
}



generate_file_paths <- function(start_year, end_year, base_path) {
  years <- start_year:end_year
  file_paths <- lapply(years, function(year) {
    paste0(base_path, "/with _HPI_data_categories", year, ".csv")
  })
  return(unlist(file_paths))
}

# Assuming base_path is defined like this (adjust according to your directories):
base_path <- here::here("..", "..", "..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306",  "with_hpi_lopnr","2.filtered")



# Generate file paths for the period 2000-2004 as an example
file_paths_2016_2021 <- generate_file_paths(2015, 2021, base_path)


# Call the function
process_datasets("2017-2021", file_paths_2016_2021)




```

# 3 Summarized data 

## 3.1 Read summarized files
```{r}



# Read in all summary files, add a 'YearGroup' column, and bind them into one dataframe
all_summarized_data <- 
  bind_rows(
    # create list of filepaths for those without HPI data
  list.files(path = here("../../../HPI (DNR XXXXXX)/Data HPI registeruttag 2023/SCB/Leverans/Leverans_20240306/without_hpi_lopnr/3.summarized"), pattern = "Summary_.*\\.csv", full.names = TRUE) %>%
    
  map_df(~{
    # Extracts year group from the filename
    year_group <- str_extract(basename(.x), "\\d{4}-\\d{4}|\\d{4}-\\d{2}") 
    
    read_csv(.x) %>%
      mutate(YearGroup = year_group,
             data = "without_HPI") 
  }),
 # create list of filepaths for those with HPI data
list.files(path = here("../../../HPI (DNR XXXXXX)/Data HPI registeruttag 2023/SCB/Leverans/Leverans_20240306/with_hpi_lopnr/3.summarized"), pattern = "Summary_.*\\.csv", full.names = TRUE) %>%
  map_df(~{
    year_group <- str_extract(basename(.x), "\\d{4}-\\d{4}|\\d{4}-\\d{2}") # Extracts year group from the filename
    
    read_csv(.x) %>%
      mutate(YearGroup = year_group,
             data = "with_HPI")
  })
)  %>% 
  # adding the 3 years or more of workplace category, consecutive years category
  bind_rows(
  bind_rows(
 read_csv(here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306", "with_hpi_lopnr", "5.work_duration", "workduration_with_summarized.csv")) %>% 
  rename( "Categories"=consecutive_years_category ,
          "Value" = percentage) %>% 
  mutate(Variable = "consecutive_years_category"),

read_csv(here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306", "with_hpi_lopnr", "5.work_duration", "workduration_without_summarized.csv")) %>% 
  rename( "Categories"=consecutive_years_category ,
          "Value" = percentage) %>% 
  mutate(Variable = "consecutive_years_category")
)
) %>% 
  select(!c(year_group, total)) 

```
## 3.2 Plot


## plot sociodemographics

## plot worklife organizational charactaristics

```{r}

library(statebins)
library(ggtext)
library(patchwork)
library(sysfonts)
library(showtextdb)
library(showtext)
library(ggchicklet)
library(scales) # For label_percent

# Load fonts --------------------------------------------------------------

font_add_google("Ubuntu", "ubuntu")
showtext_auto()

bg_col <- "white"
text_col <- "black"
body_font <- "ubuntu"
title_font <- "ubuntu"

 
  diff = diff_relative_ratio
  label_diff = diff_relative_ratio
  
  
#############################################################################  
# plot data
#############################################################################  
  
  bins_plot_data <-
  all_summarized_data %>% 
    pivot_wider(names_from =  data , values_from = c(n, Value)) %>% 
    mutate(
      Categories = if_else(Variable=="Sex",
                           recode(Categories,
                          "1" = "Men",
                          "2" = "Women"
      ), Categories),
    Variable = recode(Variable,
      "Sex" = "Sex",
      "AgeGroup" = "Age group",
      "Place_of_origin" = "Place of birth",
      "Civil_status" = "Civil status",
      "KommunSize" = "Municipality",
      "EducationLevel" = "Education",
      "SSYK" = "Occupation",
      "IncomeLevel" = "Income (% of median)",
      "Income_Sources_Category" = "Income Sources",
      "consecutive_years_category" = "Contractual temporariness",
      "Ownership_sector" = "Ownership sector",
      "Number_of_employees_Category" = "Number of employees",
      "SNI_group" = "Economic sector",
      "Operatingprofit_category" = "Operating profit (% of median)",
      "Operating_Profit_Margin_Category" = "Operating profit margin",
      "Turnover_Rate_Category" = "Staff turnover"
    ),
     Variable = factor(Variable, levels = c(
       # demographics
      "Sex", 
      "Age group",  
      "Place of birth", 
      "Civil status", 
      "Municipality", 
      "Education", 
      "Occupation", 
      "Income (% of median)", 
      "Income Sources", 
      "Contractual temporariness",
      # worklife
      "Ownership sector", 
      "Number of employees", 
      "Economic sector", 
      "Operating profit (% of median)", 
      "Operating profit margin", 
      "Staff turnover"))) %>% 
  mutate(
    diff_absolute = Value_with_HPI - Value_without_HPI,
    diff_relative_ratio = round(Value_with_HPI/Value_without_HPI,2), # as a ratio
    diff_relative_percent = (Value_with_HPI - Value_without_HPI) / Value_without_HPI * 100, 
          diff_percent =scales::label_percent(accuracy = 0.1)(diff_absolute / 100), # Convert diff to percentage and format
    diff_relative_percent_label = scales::label_percent(accuracy = 0.1)(diff_relative_percent / 100)) #%>% filter(Variable == "consecutive_years_category")
  
  
  
  
  
#############################################################################  
  # sociodemographics plot data
#############################################################################  
  
     order_category_sociodemographic <-
   c(
  rev(c("18-35", "36-50", "51-65", ">65")), # AgeGroup
  rev(c("Men", "Women")), # Sex
  rev(c("Sweden", "Europe", "Outside Europe")),  # Place_of_origin
  rev(c("Partner", "Single")),
  rev(c("Metropolitan municipalities", "Dense municipalities", "Rural municipalities")),
  rev(c("Tertiary", "Secondary", "Primary")),
  rev(c("Military", "Managers", "Science and engineering", "Health care", "Education", "Other professionals", "Associate professionals", "Administration and customer service", "Personal care", "Service and shop sales", "Agriculture and forestry", "Building", "Manufacturing", "Transport", "Mechanical manufacturing", "Cleaners", "Other elementary occupations")),
  rev(c("≥200%", "120–199%", "80–119%", "60–79%", "<60%")),
  rev(c("1", "2 to 3", "≥4")),
  rev(c(">=3 years", "<3 years"))
)
  
  
    bins_plot_data %>% #filter(Variable=="Occupation") %>%  count(Categories)
  filter(
    Variable %in% c(  
      "Sex",
  "Age group",
  "Place of birth",
  "Civil status",
  "Municipality",
  "Education",
  "Occupation",
  "Income (% of median)",
  "Income Sources",
  "Contractual temporariness"
  )
  ) %>% 
      mutate(Categories = factor(Categories, levels = 
                                   
                                   order_category_sociodemographic)) %>% 
  drop_na() %>% 
  mutate(text_color = if_else(diff_absolute < -15 | diff_absolute > 15, "white", "black")) %>%

  ggplot(
   aes(x = YearGroup, y = Categories, fill = diff_absolute)
   ) +
  statebins:::geom_rtile(
    radius = unit(3, "pt"),
  #  position = position_dodge(1),
   height =.95, 
   width = .95
  ) +
   geom_text(aes(label = diff_percent,  color = text_color)) +
  # scico::scale_fill_scico(palette = 'lipari') +
  # 
  # scale_fill_gradientn(colors = c(  "#ca9b1a", "#e3b44a", "#f5cc79", "#fae3ac", "#fdf1d6",
  # "white",
  # "#c4e2e1", "#88d4d2", "#4bc6c3", "#1ebbbf", "#189a91"),
  # values = scales::rescale(c(-1, 0, 1))) +
  
    scale_fill_gradientn(colors = c("#003B46", "#07575B", "#66A5AD", "#C4DFE6", "#E6F1F5", "#FFD1AA", "#FFA07A", "#F08030"),
#  values = scales::rescale(c(-1, 0, 1)),
   values = rescale(c(-20, 0, 20)),  # Ensure infinite values are accounted for
    limits = c(-20, 20),  # Limits set to -20 and 20
    na.value = "black",  # Any NA values or out-of-bounds will be black
   # oob = scales::oob_squish  # Squish out-of-bounds values into the limits
  ) +
      scale_color_identity() + # Use the color identity scale to apply the colors directly
  scale_x_discrete(labels = c("95-99", "00-04", "05-09", "10-14", "15-19", "20-21"),
                   position = "top",
                   guide = guide_axis(n.dodge = 2)) + 
  #coord_fixed() +
  ggforce::facet_col(~Variable, 
                     scales = 'free_y', 
                     space = 'free',
                     strip.position = 'top')+
  #facet_wrap(~group, ncol = 1, scales = "free_y") +
  #theme_void(base_size = 32, base_family = "Oficial") +

  theme(
   # aspect.ratio = .2,
    
    legend.position = "bottom",
    plot.background = element_rect(fill = bg_col, colour = bg_col),
    panel.background = element_rect(fill = bg_col, colour = bg_col),
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(),
    axis.title = element_blank(),
    axis.text.y = element_text(colour = text_col,
                               hjust = 1,
                               margin = margin(r = 0),
                               angle=0),
    axis.text.x = element_text(colour = text_col,
                               hjust = .5,
                               margin = margin(r = 0),
                               angle=0),
    axis.line.x = element_line(),
    axis.ticks.x = element_line(),
    plot.title.position = "plot",
    plot.caption.position = "plot",
    strip.text = element_text(face = "bold", color = "grey10", 
                              size = 10,
                              hjust = 0,
                              margin = margin(t = 0, r = 0, b = 0, l = 0)),
    strip.background = element_rect(fill = "white", color = "white"),
    plot.margin = margin(t=10, r=-0, b=10, l=0),
    plot.title = element_textbox_simple(
      colour = text_col,
      hjust = 0.5,
      halign = 0,
      size = rel(1.8),
      face = "bold",
      margin = margin(b = 10, t = 10),
      lineheight = 0.5#,
      #family = body_font
    )
  )
  
  
  
ggsave("plotscbpopulation_reldiff_percent.pdf", height = 20, width = 10)
ggsave("plotscbpopulation_reldiff.pdf", height = 20, width = 10)

ggsave("plotscbpopulation.pdf", height = 20, width = 10)


#############################################################################  
# worklife plot data
#############################################################################  

order_category_worklife <- c(
  rev(c("Private", "Public Regional", "Public Govermental")), # Ownership sector
  rev(c("1 to 9", "10 to 49", "50 to 249", "≥250")), # Number of employees
  rev(c(
    "Agriculture, forestry and fishing", "Mining and quarrying", "Manufacturing",
    "Electricity, gas, steam and air conditioning supply", "Water supply; sewerage, waste management and remediation activities",
    "Construction", "Wholesale and retail trade; repair of motor vehicles and motorcycles",
    "Transportation and storage", "Accommodation and food service activities",
    "Information and communication", "Financial and insurance activities",
    "Real estate activities", "Professional, scientific and technical activities",
    "Administrative and support service activities", "Public administration and defence; compulsory social security",
    "Education", "Human health and social work activities", "Arts, entertainment and recreation",
    "Other service activities", "Activities of households as employers; undifferentiated goods- and services-producing activities of households for own use",
    "Activities of extraterritorial organisations and bodies" # Economic sector
  )),
  rev(c(">500%", "0% to 500%", "-500% to 0%", "<-500%")), # Operating profit (% of median)
  rev(c(">5%", "0% to 5%", "-5% to 0%", "<-5%")), # Operating profit margin
  rev(c("<10%", "10% to 20%", "≥20%")) # Staff turnover
)


    bins_plot_data %>%
  filter(
    Variable %in% c(  
  "Ownership sector",
  "Number of employees",
  "Economic sector",
  "Operating profit (% of median)",
  "Operating profit margin",
  "Staff turnover"
  )
  ) %>% 
      mutate(Categories = factor(Categories, levels = 
                                   
                                   order_category_worklife)) %>% 
  drop_na() %>% 
  mutate(text_color = if_else(diff_absolute < -10, "white", "black")) %>%

  ggplot(
   aes(x = YearGroup, y = Categories, fill = diff_absolute)
   ) +
  statebins:::geom_rtile(
    radius = unit(3, "pt"),
  #  position = position_dodge(1),
   height =.95, 
   width = .95
  ) +
   geom_text(aes(label = diff_percent,  color = text_color)) +
  # scico::scale_fill_scico(palette = 'lipari') +
  # 
  # scale_fill_gradientn(colors = c(  "#ca9b1a", "#e3b44a", "#f5cc79", "#fae3ac", "#fdf1d6",
  # "white",
  # "#c4e2e1", "#88d4d2", "#4bc6c3", "#1ebbbf", "#189a91"),
  # values = scales::rescale(c(-1, 0, 1))) +
  
    scale_fill_gradientn(colors = c("#003B46", "#07575B", "#66A5AD", "#C4DFE6", "#E6F1F5", "#FFD1AA", "#FFA07A", "#F08030"),
  values = scales::rescale(c(-1, 0, 1))) +
      scale_color_identity() + # Use the color identity scale to apply the colors directly
  scale_x_discrete(labels = c("95-99", "00-04", "05-09", "10-14", "15-19", "20-21"),
                   position = "top",
                   guide = guide_axis(n.dodge = 2)) + 
  #coord_fixed() +
  ggforce::facet_col(~Variable, 
                     scales = 'free_y', 
                     space = 'free',
                     strip.position = 'top')+
  #facet_wrap(~group, ncol = 1, scales = "free_y") +
  #theme_void(base_size = 32, base_family = "Oficial") +

  theme(
   # aspect.ratio = .2,
    
    legend.position = "bottom",
    plot.background = element_rect(fill = bg_col, colour = bg_col),
    panel.background = element_rect(fill = bg_col, colour = bg_col),
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(),
    axis.title = element_blank(),
    axis.text.y = element_text(colour = text_col,
                               hjust = 1,
                               margin = margin(r = 0),
                               angle=0),
    axis.text.x = element_text(colour = text_col,
                               hjust = .5,
                               margin = margin(r = 0),
                               angle=0),
    axis.line.x = element_line(),
    axis.ticks.x = element_line(),
    plot.title.position = "plot",
    plot.caption.position = "plot",
    strip.text = element_text(face = "bold", color = "grey10", 
                              size = 10,
                              hjust = 0,
                              margin = margin(t = 0, r = 0, b = 0, l = 0)),
    strip.background = element_rect(fill = "white", color = "white"),
    plot.margin = margin(t=10, r=-0, b=10, l=0),
    plot.title = element_textbox_simple(
      colour = text_col,
      hjust = 0.5,
      halign = 0,
      size = rel(1.8),
      face = "bold",
      margin = margin(b = 10, t = 10),
      lineheight = 0.5#,
      #family = body_font
    )
  )
  



c("#5B92E5", "#A1C4F5", "#DCE4F6", "#FFFFFF", "#FFD1AA", "#FFA07A", "#F06030")
c("#9B59D0", "#C2A5DE", "#E1D3EC", "#F2F2F2", "#C5E1A5", "#9CCC65", "#7CB342")
c("#35978F", "#79BFA1", "#B8E2C8", "#E6F2E4", "#FFF2AC", "#FFD966", "#FFC107")
c("#003B46", "#07575B", "#66A5AD", "#C4DFE6", "#FFD1AA", "#FFA07A", "#F08030")
c("#003B46", "#07575B", "#66A5AD", "#C4DFE6", "#E6F1F5", "#FFD1AA", "#FFA07A", "#F08030")

c("#8C564B", "#C49C94", "#E4D6C3", "#F7F7F7", "#C7E9C0", "#A1D99B", "#74C476")
c("#7B3294", "#C2A5CF", "#F7F7F7", "#FFF7BC", "#FDBB84", "#E34A33")


c("#173D60", "#515A79" ,"#775E72", "#FDF4D9", "#E6C398", "#E99973", "#A36267") 


```




## 3.2 Grouped over and underreached


**variables**
Individnivå: Sex, AgeGroup, Place_of_origin, SSYK, consecutive_years.
Strukturnivå: SNI_group, Number_of_employees_Category, Turnover_Rate_Category, KommunSize 

EducationLevel, IncomeLevel

**Ideas**
https://www.quora.com/How-do-I-find-variable-importance-in-random-forest
https://chat.openai.com/share/49ba24b8-39e6-4214-8f83-2d01ec1ae4a9 
random sampling to the population and then 


# Logistic regression for dataset membership prediction
model <- glm(dataset ~ sex * age_group * occupation * private_vs_gov * num_employees, family = "binomial", data = combined)

Using machine learning techniques like Random Forests can help identify the most important predictors and understand complex interactions, which might not be easily noticeable:


library(randomForest)
rf_model <- randomForest(dataset ~ sex + age_group + occupation + private_vs_gov + num_employees + ..., data = combined, importance = TRUE)
varImpPlot(rf_model)

### Read in HPI data
```{r}


 hpa <- read_csv(here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "HPI", "HPI clean", "EEB_hpb_clean_2023-10-16.csv")) %>% 
   filter(rowSums(!is.na(select(., EkB_rel_VO2, Astrand_rel_VO2, HeightCM, WeightKG, BloodPressureSystolic, BloodPressureDiastolic))) >= 2,
         rowSums(!is.na(select(., ExerciseAnswer, TobaccoSmoking, Diet, Health, StressOverall, SymptomBackNeck))) >= 2) %>% 
     arrange(LopNr, Performed) %>% 
  mutate(hpa_number = row_number(), 
         test_count = n(), .by = LopNr) %>% 
    # take the first hpi tests
  filter(hpa_number == 1) %>% 
   select(LopNr, Year, Performed) %>% filter(Year >2014, Year < 2022) 
   #mutate(selected = 1)
  
  # 3. Randomly sample one of each LopNr
  sampled_data <-  
    datasets %>% 
    # join by lopnr and Year with HPI data
    left_join(hpa, by = join_by(LopNr, Year)) %>% 
    # filter those that has an HPI test
    filter(selected==1)  #%>


# List of years for the datasets
years <- 2015:2021

# Base path to the files
base_path <- file.path("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306", "with_hpi_lopnr", "2.filtered")

# Variables to extract from each dataset
columns_to_keep <- c("LopNr", "Year", "Sex", "AgeGroup", "Place_of_origin", 
                     "SSYK", "SNI_group", "Number_of_employees_Category", 
                     "Turnover_Rate_Category", "KommunSize", "EducationLevel", "IncomeLevel")


# Function to read, sample, and return the dataset
read_and_sample <- function(years) {
  
   # Construct file name and path
  file_name <- sprintf("with_HPI_data_categories%d.csv", years)
  file_path <- file.path(base_path, file_name)

 year <- str_extract(basename(file_path), "\\d{4}") # Extract the year from the file name
  # Read the data
  df <- read_csv(file_path) %>% mutate(Year = as.numeric(year)) # Add the Year variable
  

  # Select the desired columns
  df <- df %>% select(all_of(columns_to_keep))
  
  
    df <- hpa %>% left_join(df, by = c("LopNr", "Year" = "Year")) %>% 
  mutate(n=n(), .by = c(LopNr, Performed)) %>% filter(n==1) %>% select(!Performed)
  
  return(df)
}

# Apply the function to each year and combine the results
combined_sample_with_df <- map_df(years, read_and_sample)

combined_sample_with_df<-combined_sample_with_df %>% drop_na() 
write_csv(combined_sample_with_df, here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306", "with_hpi_lopnr", "7.fig3data", "fig3data_with.csv"))

```


### Read in a sample of the population data

Place_of_origin, Civil_status, EducationLevel, Ssyk3_minorlevel, SSYK, IncomeLevel, KommunSize, LoneInk, Income_Sources_Category,
# worklife organisational
Ownership_sector, Number_of_employees_Category, Turnover_Rate_Category, Operating_Profit_Margin, Operating_Profit_Margin_Category, Operatingprofit_category, SNI_group, SsykAr,

here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306", "with_hpi_lopnr", "2.filtered")
"consecutive_years", 

```{r}
# Define the sample size per dataset
sample_size <- 30000  

# List of years for the datasets
years <- 2015:2021

# Base path to the files
base_path <- file.path("..", "..", "..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", 
                        "SCB", "Leverans", "Leverans_20240306", "without_hpi_lopnr", "2.filtered")

# Variables to extract from each dataset
columns_to_keep <- c("LopNr", "Sex", "AgeGroup", "Place_of_origin", 
                     "SSYK", "SNI_group", "Number_of_employees_Category", 
                     "Turnover_Rate_Category", "KommunSize", "EducationLevel", "IncomeLevel")

# Function to read, sample, and return the dataset
read_and_sample <- function(year) {
  # Construct file name and path
  file_name <- sprintf("without_HPI_data_categories%d.csv", year)
  file_path <- file.path(base_path, file_name)
  
  
  
  # Read the data
  df <- read.csv(file_path)
  
  # add year
  df$year <- year
  # Select the desired columns
  df <- df %>% select(all_of(columns_to_keep))
  
  # Sample the dataset
  set.seed(123)  # for reproducibility
  df_sampled <- sample_n(df, sample_size)
  
  return(df_sampled)
}

# Apply the function to each year and combine the results
combined_sample_without_df <- map_df(years, read_and_sample)


write_csv(combined_sample_without_df, here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306", "without_hpi_lopnr", "7.fig3data", "fig3data_without.csv"))
```

# random forrest

```{r}
library(tidymodels)


# Step 1: Load Data
combined <- bind_rows(
  read_csv(here::here("..", "..", "..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306", "without_hpi_lopnr", "7.fig3data", "fig3data_without.csv")) %>% mutate(dataset="Population"),
  read_csv(here::here("..", "..", "..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306", "with_hpi_lopnr", "7.fig3data", "fig3data_with.csv")) %>% mutate(dataset="HPA") 
) %>% mutate(dataset = as.factor(dataset)) %>% select(!c(Year, Performed, n))

combined <- combined %>% drop_na() %>% mutate(all = str_c(Sex, AgeGroup, Place_of_origin, SSYK, Number_of_employees_Category, Turnover_Rate_Category, KommunSize))
combined %>% count(dataset)
# Step 2: Create a Random Forest Model Specification
rf_spec <- rand_forest(
  trees = 1000,  # Adjust the number of trees
  mode = "classification"
) %>% 
  set_engine("ranger", importance = 'impurity') %>% 
  set_mode("classification")

# Step 3: Create a Recipe
recipe <- recipe(dataset ~ ., data = combined) %>% 
  step_rm(LopNr,EducationLevel, IncomeLevel) %>%  # Remove non-predictive variables (e.g., ID numbers)
  step_novel(all_nominal(), -all_outcomes()) %>% 
  step_dummy(all_nominal(), -all_outcomes()) 


recipe <- recipe(dataset ~ ., data = combined) %>% 
  step_rm(LopNr,EducationLevel, IncomeLevel) %>%  # Remove non-predictive variables (e.g., ID numbers)
  step_novel(all) %>% 
  step_dummy(all) 
# Step 4: Prepare Data Split
set.seed(123)
data_split <- initial_split(combined, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)

# Step 5: Fit the Model
rf_fit <- workflow() %>% 
  add_model(rf_spec) %>% 
  add_recipe(recipe) %>% 
  fit(data = train_data)

# Step 6: Evaluate the Model
rf_results <- rf_fit %>%
  predict(test_data) %>%
  bind_cols(test_data) %>%
  metrics(truth = dataset, estimate = .pred_class)

rf_results


rf_fit %>% 
  extract_fit_parsnip() %>% 
  vip::vip(num_features = 20)

vip::vip(rf_fit, num_features = 10)
```

```{r}

combinedX <- combined %>% drop_na() %>% mutate(all = str_c(Sex, AgeGroup, Place_of_origin, SSYK, Number_of_employees_Category, Turnover_Rate_Category, KommunSize)) %>% 
  dplyr::select(dataset, all)
# Step 2: Create a Random Forest Model Specification
rf_spec <- rand_forest(
  trees = 100,  # Adjust the number of trees
  mode = "classification"
) %>% 
  set_engine("ranger", importance = 'impurity') %>% 
  set_mode("classification")

# Step 3: Create a Recipe
# Update the recipe to handle high cardinality
recipe <- recipe(dataset ~ ., data = combinedX) %>%
  step_other(all, threshold = 0.05) %>%  # Group infrequent levels into 'other'
  step_novel(all) %>%
  step_dummy(all)
# Step 4: Prepare Data Split
set.seed(123)
data_split <- initial_split(combinedX, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)

# Step 5: Fit the Model
rf_fit <- workflow() %>% 
  add_model(rf_spec) %>% 
  add_recipe(recipe) %>% 
  fit(data = train_data)

# Step 6: Evaluate the Model
rf_results <- rf_fit %>%
  predict(test_data) %>%
  bind_cols(test_data) %>%
  metrics(truth = dataset, estimate = .pred_class)

rf_results


rf_fit %>% 
  extract_fit_parsnip() %>% 
  vip::vip(num_features = 20)

vip::vip(rf_fit, num_features = 10)
```



https://www.tidymodels.org/start/case-study/


```{r}
model <- glm(dataset ~ Sex * AgeGroup * Number_of_employees_Category *Place_of_origin, family = "binomial", data = combined)
broom::tidy(model, exponentiate = TRUE)
```

```{r}
# Random Forest Model Specification with OOB
rf_spec <- rand_forest(
  trees = 1000,  # Adjust the number of trees
  mode = "classification",
  mtry = 2,  # Adjust based on number of predictors
  min_n = 10  # Minimum number of data points in a node
) %>% 
  set_engine("ranger", importance = 'impurity', save_pred = TRUE) %>% 
  set_mode("classification")

# Prepare the recipe
recipe <- recipe(dataset ~ ., data = combined) %>% 
  step_rm(LopNr) %>%  # Exclude non-predictive variables
  step_novel(all_nominal(), -all_outcomes()) %>% 
  step_dummy(all_nominal(), -all_outcomes())

# Fit the Model
rf_fit <- workflow() %>% 
  add_model(rf_spec) %>% 
  add_recipe(recipe) %>% 
  fit(data = combined)  # Using all data

# Extracting OOB Error and Feature Importance
rf_fit %>%
  pull_workflow_fit() %>%
  pluck("fit") %>%
  ranger::importance()  # Check the importance of each feature
```

# calculating proportions

```{r}
combined <- bind_rows(
  read_csv(here::here("..", "..", "..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306", "without_hpi_lopnr", "7.fig3data", "fig3data_without.csv")) %>% mutate(dataset="Population"),
  read_csv(here::here("..", "..", "..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20240306", "with_hpi_lopnr", "7.fig3data", "fig3data_with.csv")) %>% mutate(dataset="HPA") 
) %>%
  mutate(dataset = as.factor(dataset)) %>%
  dplyr::select(Sex, AgeGroup, Place_of_origin, SSYK, Number_of_employees_Category, Turnover_Rate_Category, KommunSize, dataset) %>% drop_na()


# Calculate proportions for each group
proportions <- combined %>%
  group_by(Sex, AgeGroup, Place_of_origin, SSYK, Number_of_employees_Category, Turnover_Rate_Category, KommunSize, dataset) %>%
  summarise(count = n(), .groups = 'drop') %>%
  group_by(dataset) %>%
  mutate(total = sum(count), proportion = count / total) %>%
  ungroup()

# Spread proportions for comparison
proportions_spread <- proportions %>%
  pivot_wider(names_from = dataset, values_from = proportion, values_fill = list(proportion = 0))


proportions_spread <- proportions_spread %>%
  mutate(difference = Population - HPA) # abs() if all positive values


# Identify the groups with the largest differences
largest_differences <- proportions_spread %>%
  arrange(difference) %>%
  head(60)  # Adjust as necessary to see more or fewer groups

# Visualization
ggplot(largest_differences, aes(x = interaction(Sex, AgeGroup, Place_of_origin, SSYK, Number_of_employees_Category, Turnover_Rate_Category, KommunSize), y = difference, fill = Sex)) +
  geom_col() +
  coord_flip() +
  labs(title = "Top Differences Between Datasets by Demographic Groups", x = "Group", y = "Difference in Proportions") +
  theme_minimal()

```


# clusters
memory.limit(size=16000)  # Size in MB, adjust based on your system's capacity
```{r}
library(dplyr)
library(tidyr)
library(cluster)  # For clustering algorithms
library(factoextra)  # For visualizing clusters


# Convert character columns to factors
combinedfactors <- proportions_spread %>% mutate(str_c)
  mutate(across(where(is.character), as.factor),
         across(where(is.numeric), as.factor))
# Calculate Gower distance
gower_dist <- daisy(combinedfactors, metric = "gower")

# Perform hierarchical clustering using average linkage
hc_gower <- hclust(gower_dist, method = "average")

# Plot the dendrogram
plot(hc_gower, main = "Hierarchical Clustering with Gower Distance")

# Cutting tree to form clusters
clusters <- cutree(hc_gower, k = 5)  # Adjust k based on your analysis

# Visualizing clusters if needed
library(factoextra)
fviz_dend(hc_gower, rect = TRUE, k = 5)
```

# grouped clusters
To calculate the grouped differences between datasets for each combination of categorical variables and then use those differences as features in a clustering analysis is an unconventional approach, but it can provide insights into which combinations of variables' categories are most distinctive in terms of representing differences between datasets. Here's a high-level outline of how you might perform such an analysis:
```{r}



contingency_table <- combined %>%
  group_by(Sex, AgeGroup, Place_of_origin, SSYK, Number_of_employees_Category, Turnover_Rate_Category, KommunSize, dataset) %>%
  tally() %>%
  pivot_wider(names_from = dataset, values_from = n, values_fill = list(n = 0)) %>%
  ungroup()

contingency_table <- contingency_table %>%
  mutate(Difference = HPA - Population)

contingency_table <- contingency_table %>%
  mutate(Combination = str_c(Sex, AgeGroup, Place_of_origin, SSYK, Number_of_employees_Category, Turnover_Rate_Category, KommunSize, sep = "_"))

# Selecting only the necessary columns for clustering
clustering_data <- contingency_table %>%
  select(Combination, Difference)


# Convert 'Difference' into a matrix format suitable for hclust()
distance_matrix <- as.dist(matrix(clustering_data$Difference))

# Perform hierarchical clustering
hc <- hclust(distance_matrix, method = "ward.D2")







# 2

grouped_differences <- combined %>%
  group_by(Sex, AgeGroup, Place_of_origin, SSYK, Number_of_employees_Category, Turnover_Rate_Category, KommunSize) %>%
  summarise(Count_Population = sum(dataset == "Population"), 
            Count_HPA = sum(dataset == "HPA"), .groups = 'drop') %>%
  mutate(Total_Count = Count_Population + Count_HPA,
         Proportion_Population = Count_Population / Total_Count,
         Proportion_HPA = Count_HPA / Total_Count,
         Difference = Proportion_HPA - Proportion_Population) %>%
  ungroup()

grouped_differences <- grouped_differences %>%
  mutate(Group_Combination = str_c(Sex, AgeGroup, Place_of_origin, SSYK, Number_of_employees_Category, Turnover_Rate_Category, KommunSize, sep = "_"))

# Select only the relevant columns for clustering
clustering_data <- grouped_differences %>%
  select(Group_Combination, Difference)


set.seed(123)  # for reproducibility
k <- 5  # Choose the number of clusters
km_result <- kmeans(clustering_data$Difference, centers = k)

# Add the cluster assignments back to the original data
clustering_data$Cluster <- km_result$cluster


clustering_data %>% arrange(Difference) %>% head(20) %>% 
ggplot( aes(x = Cluster, y = Group_Combination, fill = Difference)) +
  geom_tile() +  # Creates a heatmap
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        axis.title = element_blank())








# Calculate mean and standard deviation of the differences
mean_difference <- mean(grouped_differences$Difference, na.rm = TRUE)
std_dev_difference <- sd(grouped_differences$Difference, na.rm = TRUE)

# Standardize differences to create a score similar to Z-score
grouped_differences <- grouped_differences %>%
  mutate(Standardized_Difference = (Difference - mean_difference) / std_dev_difference)

# Rescale to -100 to 100 range
grouped_differences <- grouped_differences %>%
  mutate(Score = Standardized_Difference * 100)


grouped_differences %>% count(Group_Combination,Score) %>% arrange(Score) %>%  print(n=1000)



library(MASS)

# Perform MDS
mds_result <- isoMDS(as.dist(1 - abs(clustering_data$Difference)))  # Convert to dissimilarity

# Create a data frame for plotting
mds_df <- data.frame(
  X = mds_result$points[, 1],
  Y = mds_result$points[, 2],
  Cluster = grouped_differences$Cluster
)

# Plot the MDS result
ggplot(mds_df, aes(x = X, y = Y, color = as.factor(Cluster))) +
  geom_point(alpha = 0.7) +
  scale_color_brewer(palette = "Set1") +
  theme_minimal() +
  labs(color = "Cluster")
```

k-modes

```{r}
library(klaR)  # K-Modes function

# Applying K-Modes Clustering
kmodes_result <- kmodes(combined[, -1], 5, iter.max = 10, weighted = FALSE)  # Exclude identifier column if present

# Viewing the clustering result
print(kmodes_result)

# Add cluster assignment to data
combined <- combined %>%
  mutate(Cluster = kmodes_result$cluster)

# Analyze cluster characteristics
cluster_summary <- combined %>%
  group_by(Cluster) %>%
  summarise(across(everything(), function(x) Mode(x)), .groups = 'drop')  # Mode function needs to be defined or use any other summary statistic

# Define a simple mode function
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

print(cluster_summary)
```


2. Logistic Regression
Fit a logistic regression model predicting dataset membership (i.e., whether a data point belongs to dataset A or B) using the categorical variables as predictors. The coefficients and odds ratios from this model can tell you which characteristics are associated with being in one dataset versus the other.

```{r}
combined_l <- combined %>%
  mutate(across(where(is.character), as.factor),
         dataset_indicator = if_else(dataset == "HPA", 1, 0))

logistic_model <- glm(dataset_indicator ~ Sex + AgeGroup + Place_of_origin + SSYK + Number_of_employees_Category + Turnover_Rate_Category + KommunSize, 
                      family = binomial(), 
                      data = combined_l)

summary(logistic_model)

# Coefficient plot
coef_df <- broom::tidy(logistic_model)

ggplot(coef_df, aes(x = estimate, y = reorder(term, estimate))) +
  geom_point() +
  geom_errorbarh(aes(xmin = estimate - std.error, xmax = estimate + std.error), height = 0) +
  labs(x = "Coefficient Estimate", y = "Predictor")

```


3. Propensity Score Matching
Calculate propensity scores for the likelihood of a data point belonging to one of the datasets based on the categorical variables. Then compare the scores to see which characteristics are more likely in one dataset compared to the other.


# MCA

```{r}
library(FactoMineR)

# Select only the categorical variables and convert them to factor if they are not already
mca_data <- combined %>%
  dplyr::select(Sex, AgeGroup, Place_of_origin, SSYK, Number_of_employees_Category, Turnover_Rate_Category, KommunSize) %>%
  mutate(across(everything(), as.factor))

# Perform MCA
mca_results <- MCA(mca_data, graph = FALSE)
mca_results$var
# Plot the results
library(factoextra)
set.seed(123)  # For reproducibility
sampled_data <- mca_data %>% dplyr::sample_n(size = 1000)  # Adjust size based on your needs

# Perform MCA on the sampled data
mca_results_sampled <- FactoMineR::MCA(sampled_data, graph = FALSE)

# Visualize the results
factoextra::fviz_mca_biplot(mca_results_sampled, choice = "mca", axes = c(1, 2),
                            geom = c("point", "text"), repel = TRUE) # Avoid text overlapping



mca_df <- as_tibble(mca_results$ind$coord) %>% janitor::clean_names()

ggplot(mca_df, aes(x = dim_1, y = dim_2)) +
  geom_density_2d_filled() + 
  theme_minimal() +
  labs(title = "Density plot of MCA results")
```


# easy way

```{r}

# Directory with summarized files 
without <- read_csv(here("../../../HPI (DNR XXXXXX)/Data HPI registeruttag 2023/SCB/Leverans/Leverans_20240306/without_hpi_lopnr/4.summarized_within_groups/2017-2021.csv"))
with <- read_csv(here("../../../HPI (DNR XXXXXX)/Data HPI registeruttag 2023/SCB/Leverans/Leverans_20240306/with_hpi_lopnr/4.summarized_within_groups/2017-2021.csv"))


comb <- with %>% left_join(without, by = join_by(AgeGroup ,  Sex ,EducationLevel  , Ssyk_majorlevel ,InstitutionCategory)) %>% 
  mutate(diff=Percent.x-Percent.y) %>% arrange(diff) %>% 
  mutate(
    AgeGroup = as.character(AgeGroup),
    Sex = as.character(Sex),
    EducationLevel = as.character(EducationLevel),
    Ssyk_majorlevel = as.character(Ssyk_majorlevel),
    InstitutionCategory = as.character(InstitutionCategory)
  ) %>% 
  mutate(
    Age_sex_education_occupation_institution = str_c(
      if_else(is.na(AgeGroup), "", AgeGroup), 
      if_else(is.na(Sex), "", Sex), 
      if_else(is.na(EducationLevel), "", EducationLevel), 
      if_else(is.na(Ssyk_majorlevel), "", Ssyk_majorlevel), 
      if_else(is.na(InstitutionCategory), "", InstitutionCategory), 
      sep = "-"
    )
  )

bind_rows(
comb %>% 
  slice_min(order_by = diff, n = 30) %>% mutate(value="1smallest"),
comb %>% 
  slice_max(order_by = diff, n = 30) %>% mutate(value="2largest")
) %>% 
    mutate(Age_sex_education_occupation_institution = factor(Age_sex_education_occupation_institution, levels = unique(Age_sex_education_occupation_institution[order(diff)]))) %>% 

  ggplot(aes(x=diff, y= Age_sex_education_occupation_institution,  fill = diff))+
  geom_col() +
  facet_wrap(~value, scales = "free_x") +
   labs(title = "Age, Sex, Education, Occupation, Institution", fill = "Diff", x= "Percentage point difference") + 
   scale_fill_gradientn(colors = c("steelblue4", "lightblue", "gold4")) +  
  theme_minimal()

ggsave("combodiff.pdf", height = 8, width = 5)
```



# XX. Testing

```{r}
glimpse(scb_2012)


# SNI 


# SSYK - use first variable that starts with Ssyk
 scb_2012 %>%
  mutate(
    SSYK_majorlevel = as.numeric(str_extract(.[[grep("^Ssyk3", names(.))[[1]]]], "^\\d"))#,
    #across(.cols = -SSYK_majorlevel)  # Placeholder for future transformations
  ) %>%
  select(SSYK_majorlevel)
# selects all  Ssyk variables
# x<-  scb_2012 %>%
#    mutate(across(starts_with("Ssyk3"), ~as.numeric(str_extract(., "^\\d")), .names = "temp_{.col}")) %>%  select(starts_with("temp_"))


  
# education

scb_2012 %>%
  mutate(
    EducationLevel = if ("Sun2000niva_old" %in% names(.)) {
      case_when(
        Sun2000niva_old %in% c("1", "2") ~ "Primary",
        Sun2000niva_old %in% c("3", "4") ~ "Secondary",
        Sun2000niva_old == "5" ~ "Tertiary <2 years",
        Sun2000niva_old %in% c("6", "7") ~ "Higher Education",
        TRUE ~ NA_character_
      )
    } else if ("Sun2020niva_old" %in% names(.)) {
      case_when(
        Sun2020niva_old %in% c("1", "2") ~ "Primary",
        Sun2020niva_old %in% c("3", "4") ~ "Secondary",
        Sun2020niva_old == "5" ~ "Tertiary <2 years",
        Sun2020niva_old %in% c("6", "7") ~ "Higher Education",
        TRUE ~ NA_character_
      )
    } else NA_character_
  )%>%  select(EducationLevel) %>% count(EducationLevel)

# as numeric
# scb_2012 %>%
#   mutate(
#     EducationLevel = if ("Sun2000niva_old" %in% names(.)) {
#       case_when(
#         as.numeric(Sun2000niva_old) %in% 1:2 ~ "Primary",
#         as.numeric(Sun2000niva_old) %in% 3:4 ~ "Secondary",
#         as.numeric(Sun2000niva_old) == 5 ~ "Tertiary <2 years",
#         as.numeric(Sun2000niva_old) %in% 6:7 ~ "Higher Education",
#         TRUE ~ NA_character_
#       )
#     } else if ("Sun2020niva_old" %in% names(.)) {
#       case_when(
#         as.numeric(Sun2020niva_old) %in% 1:2 ~ "Primary",
#         as.numeric(Sun2020niva_old) %in% 3:4 ~ "Secondary",
#         as.numeric(Sun2020niva_old) == 5 ~ "Tertiary <2 years",
#         as.numeric(Sun2020niva_old) %in% 6:7 ~ "Higher Education",
#         TRUE ~ NA_character_
#       )
#     } else NA_character_
#   )

# SyssStat


# Instkod

scb_2012 %>%
  mutate(
    InstitutionCategory = if ("InstKod" %in% names(.)) {
      case_when(
        substr(InstKod, 3, 3) %in% c("1", "2") ~ "Offentligt",
        TRUE ~ "Privat"
      )
    } else if ("InstKod6" %in% names(.)) {
      case_when(
        substr(InstKod6, 4, 4) %in% c("1", "2") ~ "Offentligt",
        TRUE ~ "Privat"
      )
    } else if ("InstKod7" %in% names(.)) {
      case_when(
        substr(InstKod7, 4, 5) %in% c("10", "20", "30") ~ "Offentligt",
        TRUE ~ "Privat"
      )
    } else if ("InstKod10" %in% names(.)) {
      case_when(
        substr(InstKod7, 7, 8) %in% c("10", "20", "30") ~ "Offentligt",
        TRUE ~ "Privat"
      )
    } else {
      NA_character_
    }
  )%>%
  select(InstitutionCategory)

# LonInk
scb_2021 %>% 
  mutate(
    Lon_Foretag = if ("LonFInk" %in% names(.)) {
      median_LoneFInk <- median(LonFInk, na.rm = TRUE)
      case_when(
        LonFInk >= 2 * median_LoneFInk ~ "≥200%",
        LonFInk >= 1.2 * median_LoneFInk & LonFInk < 2 * median_LoneFInk ~ "120–199%",
        LonFInk >= 0.8 * median_LoneFInk & LonFInk < 1.2 * median_LoneFInk ~ "80–119%",
        LonFInk >= 0.6 * median_LoneFInk & LonFInk < 0.8 * median_LoneFInk ~ "60–79%",
        LonFInk < 0.6 * median_LoneFInk ~ "<60%",
        TRUE ~ NA_character_
      )
    } else if ("ArsLonFInk" %in% names(.)) {
      median_ArsLonFInk <- median(ArsLonFInk, na.rm = TRUE)
      case_when(
        ArsLonFInk >= 2 * median_ArsLonFInk ~ "≥200%",
        ArsLonFInk >= 1.2 * median_ArsLonFInk & ArsLonFInk < 2 * median_ArsLonFInk ~ "120–199%",
        ArsLonFInk >= 0.8 * median_ArsLonFInk & ArsLonFInk < 1.2 * median_ArsLonFInk ~ "80–119%",
        ArsLonFInk >= 0.6 * median_ArsLonFInk & ArsLonFInk < 0.8 * median_ArsLonFInk ~ "60–79%",
        ArsLonFInk < 0.6 * median_ArsLonFInk ~ "<60%",
        TRUE ~ NA_character_
      )
    } else NA_character_
  ) %>%  select(Lon_Foretag)


scb_2012 %>% select(Ftg_Rorelseresultat)
  mutate(
    net_sales_category = if ("Ftg_Nettoomsattning" %in% names(.)) {
      median_Ftg_Nettoomsattning <- median(Ftg_Nettoomsattning, na.rm = TRUE)
      case_when(
        Ftg_Nettoomsattning >= 2 * median_Ftg_Nettoomsattning ~ "≥200%",
        Ftg_Nettoomsattning >= 1.2 * median_Ftg_Nettoomsattning & Ftg_Nettoomsattning < 2 * median_Ftg_Nettoomsattning ~ "120–199%",
        Ftg_Nettoomsattning >= 0.8 * median_Ftg_Nettoomsattning & Ftg_Nettoomsattning < 1.2 * median_Ftg_Nettoomsattning ~ "80–119%",
        Ftg_Nettoomsattning >= 0.6 * median_Ftg_Nettoomsattning & Ftg_Nettoomsattning < 0.8 * median_Ftg_Nettoomsattning ~ "60–79%",
        Ftg_Nettoomsattning < 0.6 * median_Ftg_Nettoomsattning ~ "<60%",
        TRUE ~ NA_character_
      )
    } else NA_character_
  ) %>% select(IncomeCategory)
  
  
  scb_2012 %>%
  mutate(
    operating_profit_category = if ("Ftg_Rorelseresultat" %in% names(.)) {
      # Directly using median in case_when conditions
      case_when(
        Ftg_Rorelseresultat >= 2 * median(Ftg_Rorelseresultat, na.rm = TRUE) ~ "≥200%",
        Ftg_Rorelseresultat >= 1.2 * median(Ftg_Rorelseresultat, na.rm = TRUE) & Ftg_Rorelseresultat < 2 * median(Ftg_Rorelseresultat, na.rm = TRUE) ~ "120–199%",
        Ftg_Rorelseresultat >= 0.8 * median(Ftg_Rorelseresultat, na.rm = TRUE) & Ftg_Rorelseresultat < 1.2 * median(Ftg_Rorelseresultat, na.rm = TRUE) ~ "80–119%",
        Ftg_Rorelseresultat >= 0.6 * median(Ftg_Rorelseresultat, na.rm = TRUE) & Ftg_Rorelseresultat < 0.8 * median(Ftg_Rorelseresultat, na.rm = TRUE) ~ "60–79%",
        Ftg_Rorelseresultat < 0.6 * median(Ftg_Rorelseresultat, na.rm = TRUE) ~ "<60%",
        TRUE ~ NA_character_
      )
    } else NA_character_
  )

  # Assuming 'translation_key_df' is your data frame containing the translation key





























 translation_key_df <-
openxlsx::read.xlsx(here::here(str_glue("../../../HPI (DNR XXXXXX)/Data HPI registeruttag 2023/SCB/Leverans/Leverans_20240306/translation_SNI-versions.xlsx"))) %>% as_tibble() %>% 
   select(version, huvudgrupp_original, avdelning_samstammig, benämning_engelska_samstammig)

# Adjust the translation key dataframe to include a uniform identifier for joining
translation_key_df <- translation_key_df %>%
  mutate(
    join_key = str_c(version, str_pad(huvudgrupp_original, width = 2, pad = "0"))
  )

# Prepare the main dataframe for joining by creating a similar join key
scb_2021 %>%
  mutate(
    AstSNI2007 = if("AstSNI2007" %in% names(.)) as.character(AstSNI2007) else NA_character_,
    AstSNI2002 = if("AstSNI2002" %in% names(.)) as.character(AstSNI2002) else NA_character_,
    AstSNI92 = if("AstSNI92" %in% names(.)) as.character(AstSNI92) else NA_character_) %>% 
  mutate(
    join_key = case_when(
      if("AstSNI2007" %in% names(.)) !is.na(AstSNI2007) ~ str_c("AstSNI2007", substr(AstSNI2007, 1, 2)),
      if("AstSNI2002" %in% names(.)) !is.na(AstSNI2002) ~ str_c("AstSNI2002", substr(AstSNI2002, 1, 2)),
      if("AstSNI92" %in% names(.)) !is.na(AstSNI92) ~ str_c("AstSNI92", substr(AstSNI92, 1, 2)),
      TRUE ~ NA_character_
    )
  ) %>% left_join(translation_key_df, by = "join_key") %>%  select(join_key)










 
 

```
AstSNI2007
AstSNI2002
AstSNI92

# ast
```{r}
scb_2021 %>%
  mutate(
    AstSNI2007 = if("AstSNI2007" %in% names(scb_2021)) as.character(AstSNI2007) else NA_character_,
    AstSNI2002 = if("AstSNI2002" %in% names(scb_2021)) as.character(AstSNI2002) else NA_character_,
    AstSNI92 = if("AstSNI92" %in% names(scb_2021)) as.character(AstSNI92) else NA_character_
  ) %>%
  rowwise() %>% # Ensure that the operations are performed row by row
  mutate(
    join_key = case_when(
      !is.na(AstSNI2007) ~ str_c("AstSNI2007_", substr(AstSNI2007, 1, 2)),
      !is.na(AstSNI2002) ~ str_c("AstSNI2002_", substr(AstSNI2002, 1, 2)),
      !is.na(AstSNI92) ~ str_c("AstSNI92_", substr(AstSNI92, 1, 2)),
      TRUE ~ NA_character_
    )
  ) %>%
  ungroup() %>%
  left_join(translation_key_df, by = c("join_key" = "join_key_column_in_translation_df"))

```


AntalSys
Vissa kategorier anställda kan inte kopplas till ett faktiskt arbetsställe (med
CFAR-nummer som identitet). För dessa individer redovisas ingen uppgift
(variabeln=0).

SUN2000Niva_Old
SUN2020Niva_Old


AntAns
LoneInk
AstSNI2007
Ftg_Nettoomsattning
Ftg_Rorelseresultat
PersOms_Harledd

InstKod 
(1990–1998)
den tredje positionen anger
ägarkategori 
Ägarkategori (position 3)
1 Statlig
2 Kommunal
9 Övrig

InstKod6
den fjärde positionen anger
ägarkategori 
(1999–2000)


InstKod7
Ägarkontroll (position 4 och 5) 2001-
10 Statligt kontrollerade enheter
20 Kommunalt kontrollerade enheter
30 Landstingskontrollerade enheter
41 Privat svenskkontrollerade enheter utan koncerntillhörighet
42 Privat svenskkontrollerade enheter med koncerntillhörighet
50 Utlandskontrollerade enheter

Den institutionella sektorkoden är från och med 2014 10-ställig:
Ägarkontroll (position 7 och 8)
Kod: Benämning:
10 Statligt kontrollerade enheter
20 Kommunalt kontrollerade enheter
30 Regionkontrollerade enheter
41 Privat svenskkontrollerade enheter utan
koncerntillhörighet
42 Privat svenskkontrollerade enheter med
koncerntillhörighet
50 Utlandskontrollerade enheter

AstSNI2007

SNI 2002, SNI 92, and SNI 2007

```{r}
e <- read_csv(here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20241013","Leverans001", "eeb_lev_1990.excluded.csv"))

f <- read_csv(here::here("..", "..","..", "HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20241013","Leverans001", "eeb_lev_1990.filtered.csv"))
```


```{r}

# Generate the sequence of years
years <- 1990:2023

# Base path template without the year
base_path <- here("HPI (DNR XXXXXX)", "Data HPI registeruttag 2023", "SCB", "Leverans", "Leverans_20241013", "Leverans002", "eeb_lev_YEAR.sas7bdat")

# Generate file paths for each year by replacing "YEAR" with actual years
file_paths <- sapply(1995:2000, function(year) {
  sub("YEAR", year, base_path)
})

# Read all files and combine them into a single dataframe
combined_data <- map_df(file_paths, read_sas)



  mutate(Period = case_when(
    Year >= 1995 & Year < 2000 ~ "1995-1999",
    Year >= 2000 & Year < 2005 ~ "2000-2004",
    Year >= 2005 & Year < 2010 ~ "2005-2009",
    Year >= 2010 & Year < 2015 ~ "2010-2014",
    Year >= 2015 & Year < 2020 ~ "2015-2019",
    Year >= 2020 & Year <= 2023 ~ "2020-2023",
    TRUE ~ NA_character_  # For years outside the specified range
  )) 
```

Sammanräknad förvärvsinkomst (Total Earned Income): This typically refers to the total income an individual earns from employment and self-employment before taxes. It can include wages, salaries, bonuses, income from freelance work, and potentially other sources of earned income. The key characteristic of this income type is that it is aggregated from multiple sources, if applicable, and reflects the total income earned from labor or business activities.

Kontant bruttolön, för samtliga anställningar (Gross Cash Salary for All Employments): This refers specifically to the gross salary received in cash for all employment positions held by an individual. It includes all forms of cash compensation from employment, such as basic pay, overtime, bonuses, and allowances, before any deductions like taxes and social security contributions. This term emphasizes the cash component of the salary and the aggregation across all employments, without considering non-cash benefits or income from self-employment.

Löne eller företagarinkomst för huvudsaklig sysselsättning (Wage or Business Income from Main Occupation): This term focuses on the income derived from an individual's primary occupation, whether it's from employment (wage) or self-employment/business activities (business income). The key aspect here is the source of the income being the main job or business venture of the individual, which could imply it's the most significant source of income, in terms of time invested or earnings, compared to other potential income-generating activities.

The main differences between these terms lie in the scope and source of the income they refer to:

Total Earned Income captures all earned income before taxes, from both employment and self-employment, making it the broadest measure.
Gross Cash Salary for All Employments is narrower, focusing only on cash earnings from employment and excludes income from self-employment and non-cash benefits.
Wage or Business Income from Main Occupation narrows the focus further to the primary source of income, distinguishing between wage income from employment and income from self-employment/business activities, but it doesn't aggregate income from secondary jobs or other minor sources.



```{r}


# data from tillväxtverket, another possibility could be skr
metropolitan_municipalities <- c("114", "123", "126", "127", "128", "136", "138", "139", "160", 
                                 "162", "163", "180", "181", "182", "183", "184", "186", "191", 
                                 "1230", "1231", "1262", "1280", "1281", "1402", "1480", "1481")

dense_municipalities <- c("115", "117", "120", "140", "187", "305", "330", "380", "381", "461", 
                          "480", "481", "483", "484", "486", "561", "562", "580", "581", "583", 
                          "584", "642", "643", "680", "682", "683", "686", "687", "760", "765", 
                          "780", "781", "880", "881", "882", "883", "884", "1060", "1080", "1082", 
                          "1233", "1261", "1263", "1272", "1275", "1282", "1277", "1282", "1283", 
                          "1285", "1286", "1287", "1290", "1292", "1380", 
                          "1382", "1401", "1407", "1440", "1441", "1472", "1482", "1484", "1485", 
                          "1486", "1487", "1488", "1489", "1490", "1492", "1493", "1494", "1495", 
                          "1496", "1497", "1498", "1499", "1715", "1761", "1780", "1781", "1782", 
                          "1784", "1785", "1862", "1880", "1881", "1883", "1884", "1907", "1960", 
                          "1961", "1980", "1981", "1982", "1983", "1984", "2062", "2080", "2081", 
                          "2085", "2104", "2180", "2181", "2262", "2280", "2281", "2380", "2523", "2580", "2581", 
                          "2582", "2583", "2584")

rural_municipalities <- c("125", "128", "188", "192", "319", "331", "360", "382", "428", "482", "488", "509", 
                          "512", "513", "560", "563", "580", "582", "586", "604", "617", "662", "665", 
                          "684", "685", "761", "763", "764", "767", "821", "834", "840", "860", "861", "862", "885", 
                          "980", "1081", "1083", "1214", "1256", "1257", "1260", "1264", "1265", 
                          "1266", "1267", "1270", "1273", "1276", "1278", "1284", "1291", "1293", "1315", 
                          "1381", "1383", "1384", "1415", "1419", "1421", "1427", "1430", "1435", 
                          "1438", "1439", "1442", "1443", "1444", "1445", "1446", "1447", "1452", 
                          "1460", "1461", "1462", "1463", "1465", "1466", "1491", "1470", "1471", "1473", 
                          "1730", "1737", "1760", "1762", "1763", "1764", "1765", "1766", "1783", "1814", 
                          "1860", "1861", "1863", "1864", "1882", "1885", "1904", "1962", "2021", 
                          "2023", "2026", "2029", "2031", 
                          "2034", "2039", "2061", "2082", "2083", "2084", "2101", "2121", "2132", 
                          "2161", "2182", "2183", "2184", "2260", "2282", "2283", "2284", "2303", 
                          "2305", "2309", "2313", "2321", "2326", "2361", "2401", "2403", "2404", 
                          "2409", "2417", "2418", "2421", "2422", "2425", "2460", "2462", "2463", 
                          "2480", "2481", "2482", "2505", "2506", "2510", "2513", "2514", "2518", 
                          "2521", "2560")





add_conditional_syssstat_filters <- function(data) {
  # Define the SyssStat* variables you're interested in
  columns_to_check <- c("SyssStatG", "SyssStat", "SyssStatJ", "SyssStat11", "SyssStat19")
  
  # Initialize a filter expression that is always true
  filter_expr <- expr(TRUE)
  
  # Dynamically update the filter expression based on column existence
  for (col in columns_to_check) {
    if (col %in% names(data)) {
      # Dynamically append the condition to the filter expression
      filter_expr <- expr(!!filter_expr & (!!sym(col) %in% c(1, 5)))
    }
  }
  
  # Apply the dynamic filter expression to the dataframe
  data %>% filter(!!filter_expr)
}



x <-
scb_2012 %>% 
left_join(grunduppgifter) %>% 
  mutate(
    Year = as.numeric(year), # Add the Year variable
    FodelseAr = as.numeric(FodelseAr),
    Age = Year - FodelseAr
  ) %>% 
  filter(Age > 17) %>%
  add_conditional_syssstat_filters() %>%
  mutate(
    AgeGroup = case_when(
      Age >= 18 & Age <= 35 ~ "18-35",
      Age > 35 & Age <= 50 ~ "36-50",
      Age > 50 & Age <= 65 ~ "51-65",
      TRUE ~ ">65"
    ),
    Sex = Kon,
    BirthPlace = case_when(
      FodelseLand_EU28 == "Sverige" ~ "Sweden",
      FodelseLand_EU28 %in% c("EU utom Norden", "Europa utom EU och Norden", "Norden utom Sverige") ~ "Europe",
      FodelseLand_EU28 %in% 'Okänt'  ~ NA_character_,
      TRUE ~ "Outside Europe"
    ),
    MarriedOrPartner = case_when(
      Civil %in% c("G", "RP") ~ "Partner",  # Married or Registered Partner
      Civil %in% c("OG", "S", "Ä", "SP", "EP") ~ "Single",  # Other categories
      TRUE ~ NA_character_  # Assign NA to cases that do not match any condition
    ),
    KommunSize = case_when(
    Kommun %in% metropolitan_municipalities ~ "metropolitan_municipalities",
    Kommun %in% dense_municipalities ~ "dense_municipalities",
    Kommun %in% rural_municipalities ~ "rural_municipalities",
    TRUE ~ NA_character_
  ),
    EducationLevel = if ("Sun2000niva_old" %in% names(.)) {
        case_when(
          Sun2000niva_old %in% c("1", "2") ~ "Primary",
          Sun2000niva_old %in% c("3", "4") ~ "Secondary",
          Sun2000niva_old == "5" ~ "Tertiary <2 years",
          Sun2000niva_old %in% c("6", "7") ~ "Higher Education",
          TRUE ~ NA_character_
        )
      } else if ("Sun2020niva_old" %in% names(.)) {
        case_when(
          Sun2020niva_old %in% c("1", "2") ~ "Primary",
          Sun2020niva_old %in% c("3", "4") ~ "Secondary",
          Sun2020niva_old == "5" ~ "Tertiary <2 years",
          Sun2020niva_old %in% c("6", "7") ~ "Higher Education",
          TRUE ~ NA_character_
        )
      } else NA_character_,
    Ssyk_majorlevel = as.numeric(str_extract(.[[grep("^Ssyk3", names(.))[[1]]]], "^\\d"))
  ) %>% 
  mutate(
    IncomeLevel = case_when(
      CSFVI >= 2 * median(CSFVI, na.rm = TRUE) ~ "≥200%",
      CSFVI >= 1.2 * median(CSFVI, na.rm = TRUE) & CSFVI < 2 * median(CSFVI, na.rm = TRUE) ~ "120–199%",
      CSFVI >= 0.8 * median(CSFVI, na.rm = TRUE) & CSFVI < 1.2 * median(CSFVI, na.rm = TRUE) ~ "80–119%",
      CSFVI >= 0.6 * median(CSFVI, na.rm = TRUE) & CSFVI < 0.8 * median(CSFVI, na.rm = TRUE) ~ "60–79%",
      CSFVI < 0.6 * median(CSFVI, na.rm = TRUE) ~ "<60%",
      TRUE ~ NA_character_
    ),
    LoneInk_grupp = case_when(
      LoneInk >= 2 * median(LoneInk, na.rm = TRUE) ~ "≥200%",
      LoneInk >= 1.2 * median(LoneInk, na.rm = TRUE) & LoneInk < 2 * median(LoneInk, na.rm = TRUE) ~ "120–199%",
      LoneInk >= 0.8 * median(LoneInk, na.rm = TRUE) & LoneInk < 1.2 * median(LoneInk, na.rm = TRUE) ~ "80–119%",
      LoneInk >= 0.6 * median(LoneInk, na.rm = TRUE) & LoneInk < 0.8 * median(LoneInk, na.rm = TRUE) ~ "60–79%",
      LoneInk < 0.6 * median(LoneInk, na.rm = TRUE) ~ "<60%",
      TRUE ~ NA_character_
    )) %>% 
    # Löne eller företagarinkomst för huvudsaklig sysselsättning
           mutate(    
             Lon_Foretag = if ("LonFInk" %in% names(.)) {
      median_LoneFInk <- median(LonFInk, na.rm = TRUE)
      case_when(
        LonFInk >= 2 * median_LoneFInk ~ "≥200%",
        LonFInk >= 1.2 * median_LoneFInk & LonFInk < 2 * median_LoneFInk ~ "120–199%",
        LonFInk >= 0.8 * median_LoneFInk & LonFInk < 1.2 * median_LoneFInk ~ "80–119%",
        LonFInk >= 0.6 * median_LoneFInk & LonFInk < 0.8 * median_LoneFInk ~ "60–79%",
        LonFInk < 0.6 * median_LoneFInk ~ "<60%",
        TRUE ~ NA_character_
      )
    } else if ("ArsLonFInk" %in% names(.)) {
      median_ArsLonFInk <- median(ArsLonFInk, na.rm = TRUE)
      case_when(
        ArsLonFInk >= 2 * median_ArsLonFInk ~ "≥200%",
        ArsLonFInk >= 1.2 * median_ArsLonFInk & ArsLonFInk < 2 * median_ArsLonFInk ~ "120–199%",
        ArsLonFInk >= 0.8 * median_ArsLonFInk & ArsLonFInk < 1.2 * median_ArsLonFInk ~ "80–119%",
        ArsLonFInk >= 0.6 * median_ArsLonFInk & ArsLonFInk < 0.8 * median_ArsLonFInk ~ "60–79%",
        ArsLonFInk < 0.6 * median_ArsLonFInk ~ "<60%",
        TRUE ~ NA_character_
      )
    } else NA_character_,
    
    net_sales_category = if ("Ftg_Nettoomsattning" %in% names(.)) {
      median_Ftg_Nettoomsattning <- median(Ftg_Nettoomsattning, na.rm = TRUE)
      case_when(
        Ftg_Nettoomsattning >= 2 * median_Ftg_Nettoomsattning ~ "≥200%",
        Ftg_Nettoomsattning >= 1.2 * median_Ftg_Nettoomsattning & Ftg_Nettoomsattning < 2 * median_Ftg_Nettoomsattning ~ "120–199%",
        Ftg_Nettoomsattning >= 0.8 * median_Ftg_Nettoomsattning & Ftg_Nettoomsattning < 1.2 * median_Ftg_Nettoomsattning ~ "80–119%",
        Ftg_Nettoomsattning >= 0.6 * median_Ftg_Nettoomsattning & Ftg_Nettoomsattning < 0.8 * median_Ftg_Nettoomsattning ~ "60–79%",
        Ftg_Nettoomsattning < 0.6 * median_Ftg_Nettoomsattning ~ "<60%",
        TRUE ~ NA_character_
      )
    } else NA_character_,
    
        operating_profit_category = if ("Ftg_Rorelseresultat" %in% names(.)) {
      # Directly using median in case_when conditions
      case_when(
        Ftg_Rorelseresultat >= 2 * median(Ftg_Rorelseresultat, na.rm = TRUE) ~ "≥200%",
        Ftg_Rorelseresultat >= 1.2 * median(Ftg_Rorelseresultat, na.rm = TRUE) & Ftg_Rorelseresultat < 2 * median(Ftg_Rorelseresultat, na.rm = TRUE) ~ "120–199%",
        Ftg_Rorelseresultat >= 0.8 * median(Ftg_Rorelseresultat, na.rm = TRUE) & Ftg_Rorelseresultat < 1.2 * median(Ftg_Rorelseresultat, na.rm = TRUE) ~ "80–119%",
        Ftg_Rorelseresultat >= 0.6 * median(Ftg_Rorelseresultat, na.rm = TRUE) & Ftg_Rorelseresultat < 0.8 * median(Ftg_Rorelseresultat, na.rm = TRUE) ~ "60–79%",
        Ftg_Rorelseresultat < 0.6 * median(Ftg_Rorelseresultat, na.rm = TRUE) ~ "<60%",
        TRUE ~ NA_character_
      )
    } else NA_character_,
    Number_of_employees_Category = case_when(
    Ast_AntalSys >= 1 & Ast_AntalSys <= 9 ~ "Micro-Enterprises: 1-9 employees",
    Ast_AntalSys >= 10 & Ast_AntalSys <= 49 ~ "Small Enterprises: 10-49 employees",
    Ast_AntalSys >= 50 & Ast_AntalSys <= 249 ~ "Medium-Sized Enterprises: 50-249 employees",
    Ast_AntalSys >= 250 ~ "Large Enterprises: 250+ employees",
    TRUE ~ NA_character_
           ),
    Income_Sources_Category = case_when(
    AntAns == 0 ~ "No Income Sources",
    AntAns == 1 ~ "Single Income Source",
    AntAns >= 2 & AntAns <= 3 ~ "Multiple Income Sources: 2-3",
    AntAns >= 4 & AntAns <= 5 ~ "Diverse Income Sources: 4-5",
    AntAns >= 6 ~ "Highly Diverse Income Sources: 6+",
    TRUE ~ NA_character_ # For handling NA values
  ),
  Turnover_Rate_Category = case_when(
    PersOms_Harledd == 0 ~ "No Turnover",
    PersOms_Harledd > 0 & PersOms_Harledd <= 1 ~ "Very Low Turnover (0.1-1.0)",
    PersOms_Harledd > 1 & PersOms_Harledd <= 2 ~ "Low Turnover (1.1-2.0)",
    PersOms_Harledd > 2 & PersOms_Harledd <= 5 ~ "Moderate Turnover (2.1-5.0)",
    PersOms_Harledd > 5 & PersOms_Harledd <= 10 ~ "High Turnover (5.1-10.0)",
    PersOms_Harledd > 10 & PersOms_Harledd <= 20 ~ "Very High Turnover (10.1-20.0)",
    PersOms_Harledd > 20 ~ "Extremely High Turnover (20.1+)",
    TRUE ~ "Unknown" # For handling NA or unexpected values
  ),
  Turnover_Rate_Percent = (PersOms_Harledd / Ast_AntalSys) * 100,
      Operating_Margin_Percent = ifelse(
      all(c("Ftg_Rorelseresultat", "Ftg_Nettoomsattning") %in% names(.)) & Ftg_Nettoomsattning != 0,
      (Ftg_Rorelseresultat / Ftg_Nettoomsattning) * 100,
      NA_real_ # Assign NA if Net Sales is zero or columns do not exist
    )
           )



calculate_percentages <- function(df, vars, group_var = NULL) {
  if (!is.null(group_var) && group_var %in% names(df)) {
    df %>%
      mutate(across(all_of(vars), as.character)) %>% # Ensure vars are characters
      select(.data[[group_var]], all_of(vars)) %>%
      pivot_longer(cols = -all_of(group_var), names_to = "Variable", values_to = "Categories") %>%
      group_by(.data[[group_var]], Variable, Categories) %>%
      summarize(n = n(), .groups = "drop_last") %>%
      group_by(.data[[group_var]], Variable) %>%
      mutate(Value = 100 * (n / sum(n))) %>%
      ungroup() %>%
      select(-sum) %>%
      rename(Value = Percent) # Ensure unified "Value" column for output
  } else {
    df %>%
      mutate(across(all_of(vars), as.character)) %>% # Ensure vars are characters
      pivot_longer(cols = all_of(vars), names_to = "Variable", values_to = "Categories") %>%
      count(Variable, Categories) %>%
      group_by(Variable) %>%
      mutate(Value = 100 * n / sum(n)) %>%
      ungroup()
  }
}


calculate_means <-  function(df, vars) {
  summaries <- lapply(vars, function(var) {
    total_count <- nrow(df)
    na_count <- sum(is.na(df[[var]]))
    non_na_count <- total_count - na_count
    mean_val <- mean(df[[var]], na.rm = TRUE)
    
    data.frame(
      Variable = rep(var, 2),
      #Categories = "", # Empty to match the desired format
      n = c(non_na_count, na_count), # Count of non-NA values for mean, and NA count
      Value = c(mean_val, NA), # Mean for non-NA, NA for the NA count row
      Categories = c("Mean", "NA Count") # Distinguishing between mean value and NA count
    ) %>% as_tibble()
  })
  
  do.call(rbind, summaries)
}


# Assuming 'sampled_data' is your data frame, and you've defined the variable lists
categorical_vars <- c("AgeGroup", "Sex", "Place_of_origin", "MarriedOrPartner", 
                      "EducationLevel", "Ssyk_majorlevel", "IncomeLevel", "LoneInk_grupp", 
                      "Lon_Foretag", "net_sales_category", "operating_profit_category", 
                      "Number_of_employees_Category", "Income_Sources_Category", 
                      "Turnover_Rate_Category")
continuous_vars <- c("Turnover_Rate_Percent", "Operating_Margin_Percent")


summary_data <- bind_rows(
  calculate_percentages(x, categorical_vars),
  calculate_means(x, continuous_vars)
)


# Summarize the data
summary_data <- summarize_data(x, categorical_vars, continuous_vars)

print(summary_data %>% mutate(Value=round(Value)), n =100)

x %>% summarize(mean(Operating_Margin_Percent, na.rm = T))
calculate_means(x, "Turnover_Rate_Percent")

summarize_data <- function(data, categorical_vars, continuous_vars, group_var = NULL) {
  # Calculate percentages for categorical variables
  cat_summary <- calculate_percentages(data, categorical_vars, group_var)
  
  # Calculate means for continuous variables
  cont_summary <- calculate_means(data, continuous_vars)
  
  # Combine the summaries
  summary <- bind_rows(cat_summary, cont_summary)
  
  return(summary)
}



x %>% count(Turnover_Rate_Percent)

calculate_percentages(x, vars = c("LoneInk_grupp", "Income_Sources_Category"))
  # Combine categorical and numerical summaries
  bind_rows(categorical_summaries, numerical_summaries) %>%
    select(Variable, Category, n, Value)
}

# Apply the function to your dataset
summary_data <- summarize_data(x)


```

###old code

```{r}
map(file_paths, ~{
  file_path <- .x
    year <- str_extract(basename(file_path), "\\d{4}") # Extract the year from the file name

  data <- read_sas(file_path) %>%
    left_join(grunduppgifter) %>% 
    mutate(Year = year, # Add the Year variable
           Age = Year - FodelseAr) %>% 
    
    filter(Age > 17,
           SyssStatG %in% c(1, 5) | SyssStat %in% c(1, 5) | SyssStatJ %in% c(1, 5) |
             SyssStat11 %in% c(1, 5) | SyssStat19 %in% c(1, 5)) %>% 

    mutate(
           AgeGroup = case_when(
    Age >= 18 & Age <= 35 ~ "18-35",
    Age > 35 & Age <= 50 ~ "36-50",
    Age > 50 & Age <= 65 ~ "51-65",
    TRUE ~ ">65"
  ),
           Sex = Kon,
           BirthPlace = case_when(
    FodelseLandEU28 == "Sverige" ~ "Sweden",
    FodelseLandEU28 %in% c("EU utom Norden", "Europa utom EU och Norden", "Norden utom Sverige") ~ "Europe",
    FodelseLandEU28 %in% 'Okänt'  ~ NA_character_,
    TRUE ~ "Outside Europe"
  ),
  MarriedOrPartner = case_when(
    Civil %in% c("G", "RP") ~ "Partner",  # Married or Registrerad Partner
    Civil %in% c("OG", "S", "Ä", "SP", "EP") ~ "Single",  # Other categories (you can specify these)
    TRUE ~ NA_character_  # Assign NA to cases that do not match any condition
  ),
  EducationLevel = if ("Sun2000niva_old" %in% names(.)) {
      case_when(
        Sun2000niva_old %in% c("1", "2") ~ "Primary",
        Sun2000niva_old %in% c("3", "4") ~ "Secondary",
        Sun2000niva_old == "5" ~ "Tertiary <2 years",
        Sun2000niva_old %in% c("6", "7") ~ "Higher Education",
        TRUE ~ NA_character_
      )
    } else if ("Sun2020niva_old" %in% names(.)) {
      case_when(
        Sun2020niva_old %in% c("1", "2") ~ "Primary",
        Sun2020niva_old %in% c("3", "4") ~ "Secondary",
        Sun2020niva_old == "5" ~ "Tertiary <2 years",
        Sun2020niva_old %in% c("6", "7") ~ "Higher Education",
        TRUE ~ NA_character_
      )
    } else NA_character_,
  Ssyk_majorlevel = as.numeric(str_extract(.[[grep("^Ssyk3", names(.))[[1]]]], "^\\d")
  ) %>% 
    # sammanräknad förvärvsinkomst
       mutate(IncomeLevel = case_when(
    CSFVI >= 2 * median(CSFVI) ~ "≥200%",
    CSFVI >= 1.2 * median(CSFVI) & CSFVI < 2 * median(CSFVI) ~ "120–199%",
    CSFVI >= 0.8 * median(CSFVI) & CSFVI < 1.2 * median(CSFVI) ~ "80–119%",
    CSFVI >= 0.6 * median(CSFVI) & CSFVI < 0.8 * median(CSFVI) ~ "60–79%",
    CSFVI < 0.6 * median(CSFVI) ~"<60%",
    TRUE ~ NA_character_
  ),
  # kontant bruttolön, för samtliga anställningar
         mutate(LoneInk_grupp = case_when(
    LoneInk >= 2 * median(LoneInk) ~ "≥200%",
    LoneInk >= 1.2 * median(LoneInk) & LoneInk < 2 * median(LoneInk) ~ "120–199%",
    LoneInk >= 0.8 * median(LoneInk) & LoneInk < 1.2 * median(LoneInk) ~ "80–119%",
    LoneInk >= 0.6 * median(LoneInk) & LoneInk < 0.8 * median(LoneInk) ~ "60–79%",
    LoneInk < 0.6 * median(LoneInk) ~"<60%",
    TRUE ~ NA_character_),
    # Löne eller företagarinkomst för huvudsaklig sysselsättning
           mutate(    
             Lon_Foretag = if ("LonFInk" %in% names(.)) {
      median_LoneFInk <- median(LonFInk, na.rm = TRUE)
      case_when(
        LonFInk >= 2 * median_LoneFInk ~ "≥200%",
        LonFInk >= 1.2 * median_LoneFInk & LonFInk < 2 * median_LoneFInk ~ "120–199%",
        LonFInk >= 0.8 * median_LoneFInk & LonFInk < 1.2 * median_LoneFInk ~ "80–119%",
        LonFInk >= 0.6 * median_LoneFInk & LonFInk < 0.8 * median_LoneFInk ~ "60–79%",
        LonFInk < 0.6 * median_LoneFInk ~ "<60%",
        TRUE ~ NA_character_
      )
    } else if ("ArsLonFInk" %in% names(.)) {
      median_ArsLonFInk <- median(ArsLonFInk, na.rm = TRUE)
      case_when(
        ArsLonFInk >= 2 * median_ArsLonFInk ~ "≥200%",
        ArsLonFInk >= 1.2 * median_ArsLonFInk & ArsLonFInk < 2 * median_ArsLonFInk ~ "120–199%",
        ArsLonFInk >= 0.8 * median_ArsLonFInk & ArsLonFInk < 1.2 * median_ArsLonFInk ~ "80–119%",
        ArsLonFInk >= 0.6 * median_ArsLonFInk & ArsLonFInk < 0.8 * median_ArsLonFInk ~ "60–79%",
        ArsLonFInk < 0.6 * median_ArsLonFInk ~ "<60%",
        TRUE ~ NA_character_
      )
    } else NA_character_,
    
    net_sales_category = if ("Ftg_Nettoomsattning" %in% names(.)) {
      median_Ftg_Nettoomsattning <- median(Ftg_Nettoomsattning, na.rm = TRUE)
      case_when(
        Ftg_Nettoomsattning >= 2 * median_Ftg_Nettoomsattning ~ "≥200%",
        Ftg_Nettoomsattning >= 1.2 * median_Ftg_Nettoomsattning & Ftg_Nettoomsattning < 2 * median_Ftg_Nettoomsattning ~ "120–199%",
        Ftg_Nettoomsattning >= 0.8 * median_Ftg_Nettoomsattning & Ftg_Nettoomsattning < 1.2 * median_Ftg_Nettoomsattning ~ "80–119%",
        Ftg_Nettoomsattning >= 0.6 * median_Ftg_Nettoomsattning & Ftg_Nettoomsattning < 0.8 * median_Ftg_Nettoomsattning ~ "60–79%",
        Ftg_Nettoomsattning < 0.6 * median_Ftg_Nettoomsattning ~ "<60%",
        TRUE ~ NA_character_
      )
    } else NA_character_,
    
        operating_profit_category = if ("Ftg_Rorelseresultat" %in% names(.)) {
      # Directly using median in case_when conditions
      case_when(
        Ftg_Rorelseresultat >= 2 * median(Ftg_Rorelseresultat, na.rm = TRUE) ~ "≥200%",
        Ftg_Rorelseresultat >= 1.2 * median(Ftg_Rorelseresultat, na.rm = TRUE) & Ftg_Rorelseresultat < 2 * median(Ftg_Rorelseresultat, na.rm = TRUE) ~ "120–199%",
        Ftg_Rorelseresultat >= 0.8 * median(Ftg_Rorelseresultat, na.rm = TRUE) & Ftg_Rorelseresultat < 1.2 * median(Ftg_Rorelseresultat, na.rm = TRUE) ~ "80–119%",
        Ftg_Rorelseresultat >= 0.6 * median(Ftg_Rorelseresultat, na.rm = TRUE) & Ftg_Rorelseresultat < 0.8 * median(Ftg_Rorelseresultat, na.rm = TRUE) ~ "60–79%",
        Ftg_Rorelseresultat < 0.6 * median(Ftg_Rorelseresultat, na.rm = TRUE) ~ "<60%",
        TRUE ~ NA_character_
      )
    } else NA_character_,
    Number_of_employees_Category = case_when(
    Ast_AntalSys >= 1 & Ast_AntalSys <= 9 ~ "Micro-Enterprises: 1-9 employees",
    Ast_AntalSys >= 10 & Ast_AntalSys <= 49 ~ "Small Enterprises: 10-49 employees",
    Ast_AntalSys >= 50 & Ast_AntalSys <= 249 ~ "Medium-Sized Enterprises: 50-249 employees",
    Ast_AntalSys >= 250 ~ "Large Enterprises: 250+ employees",
    TRUE ~ NA_character_
           ),
    Income_Sources_Category = case_when(
    AntAns == 0 ~ "No Income Sources",
    AntAns == 1 ~ "Single Income Source",
    AntAns >= 2 & AntAns <= 3 ~ "Multiple Income Sources: 2-3",
    AntAns >= 4 & AntAns <= 5 ~ "Diverse Income Sources: 4-5",
    AntAns >= 6 ~ "Highly Diverse Income Sources: 6+",
    TRUE ~ NA_character_ # For handling NA values
  ),
  Turnover_Rate_Category = case_when(
    PersOms_Harledd == 0 ~ "No Turnover",
    PersOms_Harledd > 0 & PersOms_Harledd <= 1 ~ "Very Low Turnover (0.1-1.0)",
    PersOms_Harledd > 1 & PersOms_Harledd <= 2 ~ "Low Turnover (1.1-2.0)",
    PersOms_Harledd > 2 & PersOms_Harledd <= 5 ~ "Moderate Turnover (2.1-5.0)",
    PersOms_Harledd > 5 & PersOms_Harledd <= 10 ~ "High Turnover (5.1-10.0)",
    PersOms_Harledd > 10 & PersOms_Harledd <= 20 ~ "Very High Turnover (10.1-20.0)",
    PersOms_Harledd > 20 ~ "Extremely High Turnover (20.1+)",
    TRUE ~ "Unknown" # For handling NA or unexpected values
  ),
  Turnover_Rate_Percent = (PersOms_Harledd / Ast_AntalSys) * 100,
  Operating_Margin_Percent = (Ftg_Rorelseresultat / Ftg_Nettoomsattning) * 100
           )
  
  # Filter data for the interested LopNr and save
  filtered_data <- filter(data, LopNr %in% interested_LopNr)
  csv_path_filtered <-  file.path(output_folder_with, paste("with_HPI_data_categories", year, ".csv", sep="")) 
  write_csv(filtered_data, csv_path_filtered)
  
  # Filter out the interested LopNr and save
  excluded_data <- filter(data, !LopNr %in% interested_LopNr)
  csv_path_excluded <- csv_path_excluded <- file.path(output_folder_without, paste("without_HPI_data_categories", year, ".csv", sep="")) 
  write_csv(excluded_data, csv_path_excluded)
})
# Note: To combine filtered data from all files into one dataframe, 
# you would read from the _filtered.csv files similarly to previous examples
filtered_csv_paths <- list.files(here::here(), pattern = "_filtered\\.csv$", full.names = TRUE)
combined_filtered_data <- map_dfr(filtered_csv_paths, read_csv, .id = "source")

# Now, `combined_filtered_data` contains all the filtered data combined

```

